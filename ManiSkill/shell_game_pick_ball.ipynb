{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Union, Literal\n",
    "\n",
    "import numpy as np\n",
    "import sapien\n",
    "import torch\n",
    "\n",
    "from mani_skill import ASSET_DIR\n",
    "from mani_skill.agents.robots.fetch.fetch import Fetch\n",
    "from mani_skill.agents.robots.panda.panda import Panda\n",
    "from mani_skill.agents.robots.panda.panda_wristcam import PandaWristCam\n",
    "from mani_skill.agents.robots.xmate3.xmate3 import Xmate3Robotiq\n",
    "from mani_skill.envs.sapien_env import BaseEnv\n",
    "from mani_skill.envs.utils.randomization.pose import random_quaternions\n",
    "from mani_skill.sensors.camera import CameraConfig\n",
    "from mani_skill.utils import common, sapien_utils\n",
    "from mani_skill.utils.building import actors\n",
    "from mani_skill.utils.io_utils import load_json\n",
    "from mani_skill.utils.registration import register_env\n",
    "from mani_skill.utils.scene_builder.table import TableSceneBuilder\n",
    "from mani_skill.utils.structs.actor import Actor\n",
    "from mani_skill.utils.structs.pose import Pose\n",
    "from mani_skill.utils.structs.types import GPUMemoryConfig, SimConfig\n",
    "\n",
    "import gymnasium as gym\n",
    "import mani_skill.envs\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'register_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m WARNED_ONCE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;129m@register_env\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShellGamePickBall-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_episode_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, asset_download_ids\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mycb\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mShellGamePickBall\u001b[39;00m(BaseEnv):\n\u001b[1;32m      6\u001b[0m     SUPPORTED_ROBOTS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpanda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpanda_wristcam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfetch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m     agent: Union[Panda, PandaWristCam, Fetch]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'register_env' is not defined"
     ]
    }
   ],
   "source": [
    "WARNED_ONCE = False\n",
    "\n",
    "@register_env(\"ShellGamePickBall-v2\", max_episode_steps=50, asset_download_ids=[\"ycb\"])\n",
    "class ShellGamePickBall(BaseEnv):\n",
    "\n",
    "    SUPPORTED_ROBOTS = [\"panda\", \"panda_wristcam\", \"fetch\"]\n",
    "    agent: Union[Panda, PandaWristCam, Fetch]\n",
    "    goal_thresh = 0.025\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        robot_uids=\"panda_wristcam\",\n",
    "        robot_init_qpos_noise=0.02,\n",
    "        num_envs=1,\n",
    "        reconfiguration_freq=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.robot_init_qpos_noise = robot_init_qpos_noise\n",
    "        self.model_id = None\n",
    "        self.all_model_ids = np.array(\n",
    "            list(\n",
    "                load_json(ASSET_DIR / \"assets/mani_skill2_ycb/info_pick_v0.json\").keys()\n",
    "            )\n",
    "        )\n",
    "        if reconfiguration_freq is None:\n",
    "            if num_envs == 1:\n",
    "                reconfiguration_freq = 1\n",
    "            else:\n",
    "                reconfiguration_freq = 0\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            robot_uids=robot_uids,\n",
    "            reconfiguration_freq=reconfiguration_freq,\n",
    "            num_envs=num_envs,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _default_sensor_configs(self):\n",
    "        pose = sapien_utils.look_at(eye=[0.3, 0, 0.6], target=[-0.1, 0, 0.1])\n",
    "        return [CameraConfig(\"base_camera\", pose, 128, 128, np.pi / 2, 0.01, 100)]\n",
    "\n",
    "    @property\n",
    "    def _default_human_render_camera_configs(self):\n",
    "        pose = sapien_utils.look_at([0.6, 0.7, 0.6], [0.0, 0.0, 0.15])\n",
    "        return CameraConfig(\"render_camera\", pose, 512, 512, 1, 0.01, 100)\n",
    "\n",
    "    def _load_agent(self, options: dict):\n",
    "        super()._load_agent(options, sapien.Pose(p=[-0.615, 0, 0]))\n",
    "\n",
    "    def _load_scene(self, options: dict):\n",
    "        global WARNED_ONCE\n",
    "        self.table_scene = TableSceneBuilder(\n",
    "            env=self, robot_init_qpos_noise=self.robot_init_qpos_noise\n",
    "        )\n",
    "        self.table_scene.build()\n",
    "\n",
    "        # randomize the list of all possible models in the YCB dataset\n",
    "        # then sub-scene i will load model model_ids[i % number_of_ycb_objects]\n",
    "        model_ids = self._batched_episode_rng.choice(self.all_model_ids, replace=True)\n",
    "        if (\n",
    "            self.num_envs > 1\n",
    "            and self.num_envs < len(self.all_model_ids)\n",
    "            and self.reconfiguration_freq <= 0\n",
    "            and not WARNED_ONCE\n",
    "        ):\n",
    "            WARNED_ONCE = True\n",
    "            print(\n",
    "                \"\"\"There are less parallel environments than total available models to sample.\n",
    "                Not all models will be used during interaction even after resets unless you call env.reset(options=dict(reconfigure=True))\n",
    "                or set reconfiguration_freq to be >= 1.\"\"\"\n",
    "            )\n",
    "\n",
    "        # TODO: \"024_bowl\" \"025_mug\" \"065-a_cups\" (a..j) red: 065-g_cups\n",
    "        id_cup =  \"025_mug\"\n",
    "        # ! MUG-1 INITIALIZATION\n",
    "        self._objs_1: List[Actor] = []\n",
    "        self.obj_heights = []\n",
    "        for i, model_id in enumerate(model_ids):\n",
    "            model_id = id_cup\n",
    "            # print(i, model_id)\n",
    "            # TODO: before official release we will finalize a metadata dataclass that these build functions should return.\n",
    "            builder = actors.get_actor_builder(\n",
    "                self.scene,\n",
    "                id=f\"ycb:{model_id}\",\n",
    "            )\n",
    "            builder.initial_pose = sapien.Pose(p=[0, 0, 0])\n",
    "            builder.set_scene_idxs([i])\n",
    "            self._objs_1.append(builder.build(name=f\"{model_id}-1-{i}\"))\n",
    "            self.remove_from_state_dict_registry(self._objs_1[-1])\n",
    "        self.mug_left = Actor.merge(self._objs_1, name=\"mug_left\")\n",
    "        self.add_to_state_dict_registry(self.mug_left)\n",
    "\n",
    "        # ! MUG-2 INITIALIZATION\n",
    "        self._objs_2: List[Actor] = []\n",
    "        self.obj_heights = []\n",
    "        for i, model_id in enumerate(model_ids):\n",
    "            model_id = id_cup\n",
    "            # print(i, model_id)\n",
    "            # TODO: before official release we will finalize a metadata dataclass that these build functions should return.\n",
    "            builder = actors.get_actor_builder(\n",
    "                self.scene,\n",
    "                id=f\"ycb:{model_id}\",\n",
    "            )\n",
    "            builder.initial_pose = sapien.Pose(p=[0, 0, 0])\n",
    "            builder.set_scene_idxs([i])\n",
    "            self._objs_2.append(builder.build(name=f\"{model_id}-2-{i}\"))\n",
    "            self.remove_from_state_dict_registry(self._objs_2[-1])\n",
    "        self.mug_center = Actor.merge(self._objs_2, name=\"mug_center\")\n",
    "        self.add_to_state_dict_registry(self.mug_center)\n",
    "\n",
    "        # ! MUG-1 INITIALIZATION\n",
    "        self._objs_3: List[Actor] = []\n",
    "        self.obj_heights = []\n",
    "        for i, model_id in enumerate(model_ids):\n",
    "            model_id = id_cup\n",
    "            # print(i, model_id)\n",
    "            # TODO: before official release we will finalize a metadata dataclass that these build functions should return.\n",
    "            builder = actors.get_actor_builder(\n",
    "                self.scene,\n",
    "                id=f\"ycb:{model_id}\",\n",
    "            )\n",
    "            builder.initial_pose = sapien.Pose(p=[0, 0, 0])\n",
    "            builder.set_scene_idxs([i])\n",
    "            self._objs_3.append(builder.build(name=f\"{model_id}-3-{i}\"))\n",
    "            self.remove_from_state_dict_registry(self._objs_3[-1])\n",
    "        self.mug_right = Actor.merge(self._objs_3, name=\"mug_right\")\n",
    "        self.add_to_state_dict_registry(self.mug_right)\n",
    "\n",
    "        self.goal_site = actors.build_cylinder(\n",
    "            self.scene,\n",
    "            radius=self.goal_thresh,\n",
    "            half_length=self.goal_thresh,\n",
    "            color=[0, 1, 0, 1],\n",
    "            name=\"goal_site\",\n",
    "            body_type=\"kinematic\",\n",
    "            add_collision=False,\n",
    "            initial_pose=sapien.Pose(),\n",
    "        )\n",
    "        self._hidden_objects.append(self.goal_site)\n",
    "\n",
    "\n",
    "        # # !!!!!!!!!!!!! BALL\n",
    "        self.ball_radius = 0.02\n",
    "        self.red_ball = actors.build_sphere(\n",
    "            self.scene,\n",
    "            radius=self.ball_radius,\n",
    "            color=np.array([255, 0, 0, 255]) / 255,  # Red color\n",
    "            name=\"red_ball\",\n",
    "            body_type=\"dynamic\",\n",
    "            initial_pose=sapien.Pose(p=[0, 0, 0]), \n",
    "        )\n",
    "        # # !!!!!!!!!!!!! BALL\n",
    "\n",
    "    def _after_reconfigure(self, options: dict):\n",
    "        self.object_zs = []\n",
    "        for i, obj_group in enumerate([self._objs_1, self._objs_2, self._objs_3]):\n",
    "            for obj in obj_group:\n",
    "                collision_mesh = obj.get_first_collision_mesh()\n",
    "                self.object_zs.append(-collision_mesh.bounding_box.bounds[0, 2])\n",
    "        self.object_zs = common.to_tensor(self.object_zs, device=self.device)\n",
    "\n",
    "\n",
    "    def _initialize_episode(self, env_idx: torch.Tensor, options: dict):\n",
    "        with torch.device(self.device):\n",
    "\n",
    "            self.cup_with_ball_number = self._batched_episode_rng.choice([0, 1, 2])\n",
    "            self.cup_with_ball_number = torch.from_numpy(self.cup_with_ball_number).to(self.device)\n",
    "\n",
    "\n",
    "            b = len(env_idx)\n",
    "            self.table_scene.initialize(env_idx)\n",
    "\n",
    "            # ! MUG-1\n",
    "            xyz = torch.zeros((b, 3))\n",
    "            xyz[:, :2] = torch.rand((b, 2)) * 0.2 - 0.1\n",
    "            # xyz[:, 0] += 0.1 # 0.15\n",
    "            xyz[:, 2] = self.object_zs[env_idx]\n",
    "            q = torch.tensor([0, 1, 2, 0]).repeat(b, 1)\n",
    "\n",
    "            self.min_dist = 0.2\n",
    "            mug_fall_height = 0.0\n",
    "            self.mug_left.set_pose(Pose.create_from_pq(p=xyz + torch.tensor([0, -self.min_dist, mug_fall_height]).repeat(b, 1), q=q))\n",
    "            self.mug_center.set_pose(Pose.create_from_pq(p=xyz + torch.tensor([0, 0, mug_fall_height]), q=q))\n",
    "            self.mug_right.set_pose(Pose.create_from_pq(p=xyz + torch.tensor([0, self.min_dist, mug_fall_height]).repeat(b, 1), q=q))\n",
    "\n",
    "\n",
    "            # !!!!!!!!!!!!! BALL\n",
    "            q = [1, 0, 0, 0]\n",
    "            ball_xyz = xyz.clone()  # Create a copy of xyz for the ball\n",
    "            for i in range(b):\n",
    "                if self.cup_with_ball_number[i] == 0: # left\n",
    "                    ball_xyz[i, :] += torch.tensor([0, -self.min_dist, self.ball_radius-self.object_zs[env_idx][i]])\n",
    "                elif self.cup_with_ball_number[i] == 1: # center\n",
    "                    ball_xyz[i, :] += torch.tensor([0, 0, self.ball_radius-self.object_zs[env_idx][i]])\n",
    "                elif self.cup_with_ball_number[i] == 2: # right\n",
    "                    ball_xyz[i, :] += torch.tensor([0, self.min_dist, self.ball_radius-self.object_zs[env_idx][i]])\n",
    "            red_ball_pose = Pose.create_from_pq(p=ball_xyz, q=q)\n",
    "            self.red_ball.set_pose(red_ball_pose)\n",
    "\n",
    "            # ! GOAL\n",
    "            goal_xyz = ball_xyz.clone() + torch.tensor([0, 0, 0.2])\n",
    "            goal_q = torch.tensor([0.707, 0, 0.707, 0]).repeat(b, 1)\n",
    "            # goal_q = torch.tensor([0.707, 0, 0.707, 0]).repeat(b, 1)  # sqrt(2)/2 â‰ˆ 0.707\n",
    "            self.goal_site.set_pose(Pose.create_from_pq(p=goal_xyz, q=goal_q))\n",
    "\n",
    "\n",
    "\n",
    "            # Initialize robot arm to a higher position above the table than the default typically used for other table top tasks\n",
    "            if self.robot_uids == \"panda\" or self.robot_uids == \"panda_wristcam\":\n",
    "                # fmt: off\n",
    "                qpos = np.array(\n",
    "                    [0.0, 0, 0, -np.pi * 2 / 3, 0, np.pi * 2 / 3, np.pi / 4, 0.04, 0.04]\n",
    "                )\n",
    "                # fmt: on\n",
    "                qpos[:-2] += self._episode_rng.normal(\n",
    "                    0, self.robot_init_qpos_noise, len(qpos) - 2\n",
    "                )\n",
    "                self.agent.reset(qpos)\n",
    "                self.agent.robot.set_root_pose(sapien.Pose([-0.615, 0, 0]))\n",
    "            elif self.robot_uids == \"xmate3_robotiq\":\n",
    "                qpos = np.array([0, 0.6, 0, 1.3, 0, 1.3, -1.57, 0, 0])\n",
    "                qpos[:-2] += self._episode_rng.normal(\n",
    "                    0, self.robot_init_qpos_noise, len(qpos) - 2\n",
    "                )\n",
    "                self.agent.reset(qpos)\n",
    "                self.agent.robot.set_root_pose(sapien.Pose([-0.562, 0, 0]))\n",
    "            else:\n",
    "                raise NotImplementedError(self.robot_uids)\n",
    "\n",
    "    def evaluate(self):\n",
    "        obj_to_goal_pos = self.goal_site.pose.p - self.red_ball.pose.p\n",
    "        is_obj_placed = torch.linalg.norm(obj_to_goal_pos, axis=1) <= self.goal_thresh\n",
    "        is_grasped = self.agent.is_grasping(self.red_ball)\n",
    "        is_robot_static = self.agent.is_static(0.2)\n",
    "        return dict(\n",
    "            is_grasped=is_grasped,\n",
    "            obj_to_goal_pos=obj_to_goal_pos,\n",
    "            is_obj_placed=is_obj_placed,\n",
    "            is_robot_static=is_robot_static,\n",
    "            is_grasping=is_grasped,\n",
    "            success=torch.logical_and(is_obj_placed, is_robot_static),\n",
    "        )\n",
    "\n",
    "    def _get_obs_extra(self, info: Dict):\n",
    "        # if not hasattr(self, 'original_poses'):\n",
    "        self.original_poses = {\n",
    "            'mug_left': self.mug_left.pose.raw_pose.clone(),\n",
    "            'mug_center': self.mug_center.pose.raw_pose.clone(),\n",
    "            'mug_right': self.mug_right.pose.raw_pose.clone(),\n",
    "            'ball': self.red_ball.pose.raw_pose.clone(),\n",
    "            'goal': self.goal_site.pose.raw_pose.clone()\n",
    "        }\n",
    "\n",
    "        TIME_OFFSET = 5 # skip 5 steps\n",
    "        # Create masks for visible/hidden states\n",
    "        hide_mask = info['elapsed_steps'] < TIME_OFFSET-1\n",
    "        # print(info['elapsed_steps'], hide_mask)\n",
    "        # show_mask = ~hide_mask\n",
    "\n",
    "        HEIGHT_OFFSET = 100\n",
    "        \n",
    "        # Update poses based on masks\n",
    "        for mug, orig_pose in zip(\n",
    "            [self.mug_left, self.mug_center, self.mug_right],\n",
    "            [self.original_poses['mug_left'], self.original_poses['mug_center'], self.original_poses['mug_right']]\n",
    "        ):\n",
    "            # print('before', orig_pose[:, 2])\n",
    "            new_pose = orig_pose.clone()\n",
    "            # if hide_mask.any():\n",
    "            # print('zero', info['elapsed_steps'] == 0)\n",
    "            new_pose[hide_mask & (info['elapsed_steps'] == 0), 2] += HEIGHT_OFFSET  # Move hidden mugs far away and below 150\n",
    "            # print('five', info['elapsed_steps'] == TIME_OFFSET)\n",
    "            new_pose[~hide_mask & (info['elapsed_steps'] == TIME_OFFSET-1), 2] -= HEIGHT_OFFSET  # Move hidden mugs far away and below 150\n",
    "            # print('after', new_pose[:, 2])\n",
    "            mug.pose = new_pose\n",
    "\n",
    "\n",
    "        # Update ball position\n",
    "        ball_pose = self.original_poses['ball'].clone()\n",
    "        self.red_ball.pose = ball_pose\n",
    "    \n",
    "        # # Update goal position\n",
    "        goal_pose = self.original_poses['goal'].clone()\n",
    "        self.goal_site.pose = goal_pose\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        obs = dict(\n",
    "            tcp_pose=self.agent.tcp.pose.raw_pose,\n",
    "            goal_pos=self.goal_site.pose.p,\n",
    "            is_grasped=info[\"is_grasped\"],\n",
    "            cup_with_ball_number=self.cup_with_ball_number,\n",
    "        )\n",
    "        if \"state\" in self.obs_mode:\n",
    "\n",
    "            obj_pose = torch.zeros_like(self.mug_left.pose.raw_pose, \n",
    "                                        device=self.mug_left.pose.raw_pose.device, \n",
    "                                        dtype=self.mug_left.pose.raw_pose.dtype)\n",
    "\n",
    "            # Create masks for each cup position\n",
    "            left_mask = (self.cup_with_ball_number == 0).unsqueeze(-1)\n",
    "            center_mask = (self.cup_with_ball_number == 1).unsqueeze(-1)\n",
    "            right_mask = (self.cup_with_ball_number == 2).unsqueeze(-1)\n",
    "\n",
    "            # Use masks to assign poses\n",
    "            obj_pose = (self.mug_left.pose.raw_pose * left_mask + \n",
    "                        self.mug_center.pose.raw_pose * center_mask + \n",
    "                        self.mug_right.pose.raw_pose * right_mask)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            tcp_to_obj_pos = torch.zeros_like(self.mug_left.pose.p, \n",
    "                                              device=self.mug_left.pose.p.device, \n",
    "                                              dtype=self.mug_left.pose.p.dtype)\n",
    "            # Calculate tcp_to_obj_pos using masks\n",
    "            tcp_to_obj_pos = (\n",
    "                (self.mug_left.pose.p - self.agent.tcp.pose.p) * left_mask +\n",
    "                (self.mug_center.pose.p - self.agent.tcp.pose.p) * center_mask +\n",
    "                (self.mug_right.pose.p - self.agent.tcp.pose.p) * right_mask\n",
    "            )\n",
    "\n",
    "\n",
    "            obj_to_goal_pos = torch.zeros_like(self.goal_site.pose.p, \n",
    "                                              device=self.goal_site.pose.p.device, \n",
    "                                              dtype=self.goal_site.pose.p.dtype)\n",
    "\n",
    "            # Calculate obj_to_goal_pos using masks\n",
    "            obj_to_goal_pos = (\n",
    "                (self.goal_site.pose.p - self.mug_left.pose.p) * left_mask +\n",
    "                (self.goal_site.pose.p - self.mug_center.pose.p) * center_mask +\n",
    "                (self.goal_site.pose.p - self.mug_right.pose.p) * right_mask\n",
    "            )\n",
    "\n",
    "            obs.update(\n",
    "                tcp_to_goal_pos=self.goal_site.pose.p - self.agent.tcp.pose.p,\n",
    "                obj_pose=obj_pose,\n",
    "                tcp_to_obj_pos=tcp_to_obj_pos,\n",
    "                obj_to_goal_pos=obj_to_goal_pos,\n",
    "            )\n",
    "        return obs\n",
    "\n",
    "    def compute_dense_reward(self, obs: Any, action: torch.Tensor, info: Dict):\n",
    "\n",
    "        info['success'] *= (info['elapsed_steps'] > 5)\n",
    "        tcp_to_obj_dist = torch.linalg.norm(\n",
    "            self.red_ball.pose.p - self.agent.tcp.pose.p, axis=1\n",
    "        )\n",
    "        reaching_reward = 1 - torch.tanh(5 * tcp_to_obj_dist)\n",
    "        reward = reaching_reward\n",
    "\n",
    "        is_grasped = info[\"is_grasped\"]\n",
    "        reward += is_grasped\n",
    "\n",
    "        obj_to_goal_dist = torch.linalg.norm(\n",
    "            self.goal_site.pose.p - self.red_ball.pose.p, axis=1\n",
    "        )\n",
    "        place_reward = 1 - torch.tanh(5 * obj_to_goal_dist)\n",
    "        reward += place_reward * is_grasped\n",
    "\n",
    "        reward += info[\"is_obj_placed\"] * is_grasped\n",
    "\n",
    "        static_reward = 1 - torch.tanh(\n",
    "            5 * torch.linalg.norm(self.agent.robot.get_qvel()[..., :-2], axis=1)\n",
    "        )\n",
    "        reward += static_reward * info[\"is_obj_placed\"] * is_grasped\n",
    "\n",
    "        reward[info[\"success\"]] = 6\n",
    "        return reward\n",
    "    \n",
    "    def compute_normalized_dense_reward(\n",
    "        self, obs: Any, action: torch.Tensor, info: Dict\n",
    "    ):\n",
    "        return self.compute_dense_reward(obs=obs, action=action, info=info) / 6\n",
    "    \n",
    "\n",
    "\n",
    "class ColorObservationWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "        init_obs = self.observation(self.base_env._init_raw_obs)\n",
    "        self.base_env.update_obs_space(init_obs)\n",
    "    \n",
    "    @property\n",
    "    def base_env(self) -> BaseEnv:\n",
    "        return self.env.unwrapped\n",
    "\n",
    "    \n",
    "    def observation(self, obs):\n",
    "        # print(self.base_env.num_envs)\n",
    "        # cup_with_ball_number = self.base_env._batched_episode_rng.choice([0, 1, 2])#, size=(self.base_env.num_envs,))\n",
    "        # cup_with_ball_number = torch.from_numpy(cup_with_ball_number).to(self.base_env.device)\n",
    "        \n",
    "        if isinstance(obs, dict):\n",
    "            obs = obs.copy()\n",
    "            obs['cup_with_ball_number'] = self.cup_with_ball_number\n",
    "        return obs\n",
    "\n",
    "\n",
    "class InitialZeroActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env, n_initial_steps=34):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            env: environment\n",
    "            n_initial_steps: number of steps with zero actions\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self.n_initial_steps = n_initial_steps\n",
    "        self.current_steps = None\n",
    "        \n",
    "    def action(self, action):\n",
    "        \"\"\"Modifies action before sending it to the environment\"\"\"\n",
    "        if self.current_steps is None or (self.current_steps < self.n_initial_steps).any():\n",
    "            # Zero out actions for environments still in initial phase\n",
    "            mask = (self.current_steps < self.n_initial_steps)\n",
    "            modified_action = action.clone()\n",
    "            modified_action[mask] = 0\n",
    "            return modified_action\n",
    "        return action\n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = super().step(action)\n",
    "        self.current_steps = info['elapsed_steps'].detach().cpu().numpy()\n",
    "        return obs, reward, terminated, truncated, info\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"Resets the step counter\"\"\"\n",
    "        obs, info = super().reset(**kwargs)\n",
    "        self.current_steps = info['elapsed_steps'].detach().cpu().numpy()\n",
    "        return obs, info\n",
    "\n",
    "# env = gym.make(\"Thimble-v1\", num_envs=num_envs, obs_mode=\"rgb\", n_initial_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are less parallel environments than total available models to sample.\n",
      "                Not all models will be used during interaction even after resets unless you call env.reset(options=dict(reconfigure=True))\n",
      "                or set reconfiguration_freq to be >= 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.cup_with_ball_number to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.cup_with_ball_number` for environment variables or `env.get_wrapper_attr('cup_with_ball_number')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 2], device='cuda:0') torch.Size([4])\n",
      "Frames Per Second = 40 / 0.9580535888671875 = 41.75131794798286, iters = 10\n"
     ]
    }
   ],
   "source": [
    "num_envs = 4\n",
    "env = gym.make(\"ShellGamePickBall-v2\", num_envs=num_envs, obs_mode=\"rgb\")\n",
    "env = ColorObservationWrapper(env)\n",
    "env = InitialZeroActionWrapper(env, n_initial_steps=30)\n",
    "SEED = 1\n",
    "obs, _ = env.reset(seed=SEED)\n",
    "print(obs['cup_with_ball_number'], obs['cup_with_ball_number'].shape)\n",
    "done = False\n",
    "start_time = time.time()\n",
    "total_rew = 0\n",
    "obs_list = []\n",
    "i = 0\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "while not done:\n",
    "    obs_list.append(copy.deepcopy(obs))\n",
    "    # obs_list.append(obs)\n",
    "    obs, rew, terminated, truncated, info = env.step(torch.from_numpy(env.action_space.sample()))\n",
    "    done = (terminated | truncated).any()\n",
    "    i += 1\n",
    "\n",
    "obs_list.append(copy.deepcopy(obs))\n",
    "# obs_list.append(obs)\n",
    "N = num_envs * info[\"elapsed_steps\"][0].item()\n",
    "dt = time.time() - start_time\n",
    "FPS = N / (dt)\n",
    "print(f\"Frames Per Second = {N} / {dt} = {FPS}, iters = {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obs_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# visualize the image data from the environment and inspect the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mobs_list\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(obs_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensor_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(obs_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensor_data\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_camera\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'obs_list' is not defined"
     ]
    }
   ],
   "source": [
    "# visualize the image data from the environment and inspect the data\n",
    "print(obs_list[0].keys())\n",
    "print(obs_list[0]['sensor_data'].keys())\n",
    "print(obs_list[0]['sensor_data']['base_camera'].keys())\n",
    "print(obs_list[0]['sensor_data']['base_camera']['rgb'].shape)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for j in range(0, 10, 2):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    for i in range(4):\n",
    "        base_camera_image = obs_list[j]['sensor_data']['base_camera']['rgb'][i].cpu().numpy()\n",
    "        hand_camera_image = obs_list[j]['sensor_data']['hand_camera']['rgb'][i].cpu().numpy()\n",
    "        combined_image = np.concatenate((base_camera_image, hand_camera_image), axis=1)\n",
    "        axs[i].imshow(combined_image)\n",
    "        axs[i].set_title(f\"iter = {j}, cup = {obs_list[j]['cup_with_ball_number'][i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRenderStepInfoWrapper\u001b[39;00m(\u001b[43mgym\u001b[49m\u001b[38;5;241m.\u001b[39mWrapper):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(env)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "class RenderStepInfoWrapper(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.step_count = 0\n",
    "        self.current_obs = None\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = super().reset(**kwargs)\n",
    "        self.step_count = info['elapsed_steps'].detach().cpu().numpy()\n",
    "        self.current_obs = obs\n",
    "        return obs, info\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = super().step(action)\n",
    "        self.current_obs = obs\n",
    "        self.step_count = info['elapsed_steps'].detach().cpu().numpy()\n",
    "        return obs, reward, terminated, truncated, info\n",
    "    \n",
    "    def render(self):\n",
    "        # Get the base render from the environment\n",
    "        frame = self.env.render()\n",
    "        frame = frame.detach().cpu().numpy()\n",
    "\n",
    "        # Add text\n",
    "        for i in range(len(frame)):\n",
    "            # Env. step\n",
    "            cv2.putText(\n",
    "                frame[i],\n",
    "                f'Step: {self.step_count[i]}',\n",
    "                (10, 30),  # position\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,  # font\n",
    "                1.0,  # font scale\n",
    "                (255, 255, 255),  # color (white)\n",
    "                2,  # thickness\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "            if self.current_obs is not None:\n",
    "                if self.current_obs[\"cup_with_ball_number\"][i] == 0:\n",
    "                    cup = 'Target: Left'\n",
    "                elif self.current_obs[\"cup_with_ball_number\"][i] == 1:\n",
    "                    cup = 'Target: Center'\n",
    "                elif self.current_obs[\"cup_with_ball_number\"][i] == 2:\n",
    "                    cup = 'Target: Right'\n",
    "                # Target cup\n",
    "                cv2.putText(\n",
    "                    frame[i],\n",
    "                    cup,\n",
    "                    (10, 60),  # position\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,  # font\n",
    "                    1.0,  # font scale\n",
    "                    (255, 255, 255),  # color (white)\n",
    "                    2,  # thickness\n",
    "                    cv2.LINE_AA\n",
    "                )\n",
    "            \n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_envs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmani_skill\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecordEpisode\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# render_mode=\"sensors\" for real observations (rgb+d) or \"rgb_array\" for external camera\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShellGamePickBall-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_envs\u001b[38;5;241m=\u001b[39m\u001b[43mnum_envs\u001b[49m, obs_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m\"\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m env \u001b[38;5;241m=\u001b[39m ColorObservationWrapper(env)\n\u001b[1;32m     10\u001b[0m env \u001b[38;5;241m=\u001b[39m InitialZeroActionWrapper(env, n_initial_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_envs' is not defined"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import mani_skill.envs\n",
    "from tqdm.notebook import tqdm\n",
    "from mani_skill.utils.wrappers import RecordEpisode\n",
    "# render_mode=\"sensors\" for real observations (rgb+d) or \"rgb_array\" for external camera\n",
    "env = gym.make(\"ShellGamePickBall-v2\", num_envs=num_envs, obs_mode=\"rgb\", render_mode=\"rgb_array\")\n",
    "env = ColorObservationWrapper(env)\n",
    "env = InitialZeroActionWrapper(env, n_initial_steps=30)\n",
    "env = RenderStepInfoWrapper(env)  # Add our new wrapper\n",
    "env = RecordEpisode(\n",
    "    env,\n",
    "    \"./videos\", # the directory to save replay videos and trajectories to\n",
    "    # on GPU sim we record intervals, not by single episodes as there are multiple envs\n",
    "    # each 100 steps a new video is saved\n",
    "    max_steps_per_video=100\n",
    ")\n",
    "# from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv\n",
    "# env = ManiSkillVectorEnv(env, num_envs=4, ignore_terminations=True, record_metrics=True)\n",
    "\n",
    "# step through the environment with random actions\n",
    "obs, _ = env.reset(seed = SEED)\n",
    "for i in tqdm(range(100)):\n",
    "    action = env.action_space.sample()\n",
    "    # action = env.action_space.sample() * 0\n",
    "    obs, reward, terminated, truncated, info = env.step(torch.from_numpy(action))\n",
    "    if (terminated | truncated).any():\n",
    "        break\n",
    "    # env.render_human() # will render with a window if possible\n",
    "env.close()\n",
    "from IPython.display import Video\n",
    "Video(\"./videos/0.mp4\", embed=True, width=640) # Watch our replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
