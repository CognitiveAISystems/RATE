{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "359d576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gymnasium\n",
    "from __future__ import annotations\n",
    "import random\n",
    "import string\n",
    "from itertools import product\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class ARShotEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Associative Retrieval (AR) with a 'shot' query.\n",
    "\n",
    "    Поток токенов:\n",
    "      - shot_mode=\"after_pairs\":\n",
    "          [! k : v !] x P  +  [! query_key : shot]          → длина T = 5*P + 4\n",
    "      - shot_mode=\"after_any_colon\":\n",
    "          [! k : v !] x P  +  [! k : v !] x E + [! k : shot] → T = 5*(P+E) + 4\n",
    "        (query_key ранее уже встречался как полная пара)\n",
    "\n",
    "    Наблюдение — один токен за шаг.\n",
    "    Награда выдаётся только, когда текущий токен == 'shot':\n",
    "        reward = 1, если действие == правильному value; иначе 0. Эпизод завершается.\n",
    "\n",
    "    Важные флаги:\n",
    "      - deterministic_vocab=True  → порядок универсума фиксирован (не зависит от seed)\n",
    "      - full_universe_vocab=True → в env.vocab добавляется весь универсум токенов по длинам\n",
    "      - randomize_pairs=True     → ключи и значения для ЭПИЗОДА случайны (но из фикс. универсума)\n",
    "      - include_pass_token=True  → добавить 'pass' к спец-токенам (можно использовать как no-op)\n",
    "\n",
    "\n",
    "    # Отображение токенов в ID и обратно\n",
    "    obs_id = env.token_to_id[\"zA\"]   # например 1287\n",
    "    print(obs_id) # 1287\n",
    "    tok = env.id_to_token[obs_id]    # вернёт \"zA\"\n",
    "    print(tok) # \"zA\"\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": []}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_pairs: int = 6,\n",
    "        rng_seed: Optional[int] = None,\n",
    "\n",
    "        # где появится shot в смысле \"сколько полных пар точно показать сначала\"\n",
    "        prefix_pairs_range: Optional[Tuple[int, int]] = None,  # по умолчанию (1, n_pairs)\n",
    "        query_from_any_shown: bool = True,  # иначе берём последний из показанных\n",
    "\n",
    "        shot_mode: str = \"after_pairs\",  # \"after_pairs\" | \"after_any_colon\"\n",
    "        max_extra_pairs_before_shot: int = 0,  # только для \"after_any_colon\"\n",
    "\n",
    "        # словари (если None — берём из универсума согласно режимам ниже)\n",
    "        keys_vocab: Optional[List[str]] = None,\n",
    "        values_vocab: Optional[List[str]] = None,\n",
    "\n",
    "        # диапазоны длин токенов (включительно); чаще всего (2,2)\n",
    "        key_token_len_range: Tuple[int, int] = (2, 2),\n",
    "        value_token_len_range: Tuple[int, int] = (2, 2),\n",
    "\n",
    "        # алфавиты для НЕДЕТЕРМИНИРОВАННОЙ генерации\n",
    "        key_charset: str = string.ascii_letters + string.digits,\n",
    "        value_charset: str = string.ascii_letters + string.digits,\n",
    "\n",
    "        # управление словарём и его стабильностью\n",
    "        deterministic_vocab: bool = True,\n",
    "        full_universe_vocab: bool = True,\n",
    "        randomize_pairs: bool = True,\n",
    "        include_pass_token: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # RNG для динамики эпизодов и (опционально) случайного выбора пар\n",
    "        self.rng = random.Random(rng_seed)\n",
    "\n",
    "        # --- проверки параметров ---\n",
    "        assert n_pairs >= 1, \"n_pairs must be >= 1\"\n",
    "        if prefix_pairs_range is None:\n",
    "            prefix_pairs_range = (1, n_pairs)\n",
    "        min_p, max_p = prefix_pairs_range\n",
    "        if not (1 <= min_p <= max_p <= n_pairs):\n",
    "            raise ValueError(\"prefix_pairs_range must satisfy 1 <= min <= max <= n_pairs\")\n",
    "        if shot_mode not in (\"after_pairs\", \"after_any_colon\"):\n",
    "            raise ValueError(\"shot_mode must be 'after_pairs' or 'after_any_colon'\")\n",
    "\n",
    "        self.n_pairs = n_pairs\n",
    "        self.prefix_pairs_range = (min_p, max_p)\n",
    "        self.query_from_any_shown = query_from_any_shown\n",
    "        self.shot_mode = shot_mode\n",
    "        self.max_extra_pairs_before_shot = max(0, int(max_extra_pairs_before_shot))\n",
    "\n",
    "        # ---- SPECIAL tokens\n",
    "        self.SPECIAL = [\"!\", \":\", \"shot\"]\n",
    "        if include_pass_token:\n",
    "            self.SPECIAL.append(\"pass\")\n",
    "        reserved = set(self.SPECIAL)\n",
    "\n",
    "        # ---- детерминированный универсум токенов по диапазону длин\n",
    "        def det_tokens_for_range(length_range: Tuple[int, int]) -> List[str]:\n",
    "            \"\"\"\n",
    "            Генерирует все токены в лексикографическом порядке по фиксированному алфавиту:\n",
    "              digits + lowercase + uppercase = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "            Для длины L: перебор product(charset, repeat=L).\n",
    "            \"\"\"\n",
    "            lo, hi = length_range\n",
    "            if lo < 1 or hi < lo:\n",
    "                raise ValueError(\"length_range must satisfy 1 <= lo <= hi\")\n",
    "            charset = \"0123456789\" + string.ascii_lowercase + string.ascii_uppercase\n",
    "            out: List[str] = []\n",
    "            for L in range(lo, hi + 1):\n",
    "                for tup in product(charset, repeat=L):\n",
    "                    out.append(\"\".join(tup))\n",
    "            # спец-строк тут нет, но фильтр оставим\n",
    "            return [t for t in out if t not in reserved]\n",
    "\n",
    "        # ---- случайная генерация токенов (используется только если deterministic_vocab=False и словари не заданы)\n",
    "        def random_tokens(need: int, charset: str, length_range: Tuple[int, int], avoid: set[str]) -> List[str]:\n",
    "            lo, hi = length_range\n",
    "            if lo < 1 or hi < lo:\n",
    "                raise ValueError(\"length_range must satisfy 1 <= lo <= hi\")\n",
    "            tokens: List[str] = []\n",
    "            seen = set(avoid)\n",
    "            attempts = 0\n",
    "            while len(tokens) < need:\n",
    "                attempts += 1\n",
    "                L = self.rng.randint(lo, hi)\n",
    "                cand = \"\".join(self.rng.choice(charset) for _ in range(L))\n",
    "                if cand and cand not in seen:\n",
    "                    tokens.append(cand)\n",
    "                    seen.add(cand)\n",
    "                if attempts > 100_000:\n",
    "                    raise RuntimeError(\"Failed to generate enough unique random tokens; enlarge charset/lengths.\")\n",
    "            return tokens\n",
    "\n",
    "        # ---- строим словари источников для выбора пар в эпизодах (keys_vocab/values_vocab) ----\n",
    "        if keys_vocab is not None:\n",
    "            seen = set()\n",
    "            keys_vocab = [t for t in keys_vocab if (t not in reserved) and (t not in seen and not seen.add(t))]\n",
    "            if len(keys_vocab) < n_pairs:\n",
    "                raise ValueError(\"Provided keys_vocab has fewer unique tokens than n_pairs.\")\n",
    "        if values_vocab is not None:\n",
    "            seen = set()\n",
    "            values_vocab = [t for t in values_vocab if (t not in reserved) and (t not in seen and not seen.add(t))]\n",
    "\n",
    "        # если словари не заданы — берём из универсума согласно режимам\n",
    "        if keys_vocab is None or values_vocab is None:\n",
    "            if deterministic_vocab:\n",
    "                key_universe = det_tokens_for_range(key_token_len_range)\n",
    "                val_universe = det_tokens_for_range(value_token_len_range)\n",
    "\n",
    "                if randomize_pairs:\n",
    "                    # случайно выбираем пары (но из фиксированного универсума)\n",
    "                    if len(key_universe) < n_pairs:\n",
    "                        raise ValueError(\"Not enough deterministic tokens for keys.\")\n",
    "                    keys_vocab = self.rng.sample(key_universe, n_pairs)\n",
    "\n",
    "                    key_set = set(keys_vocab)\n",
    "                    val_candidates = [t for t in val_universe if t not in key_set]\n",
    "                    if len(val_candidates) < n_pairs:\n",
    "                        raise ValueError(\"Not enough deterministic tokens for values after excluding keys.\")\n",
    "                    values_vocab = self.rng.sample(val_candidates, n_pairs)\n",
    "                else:\n",
    "                    # берём первые n_pairs (фиксировано; пары не рандомизируются)\n",
    "                    if len(key_universe) < n_pairs:\n",
    "                        raise ValueError(\"Not enough deterministic tokens for keys.\")\n",
    "                    keys_vocab = key_universe[:n_pairs]\n",
    "\n",
    "                    key_set = set(keys_vocab)\n",
    "                    val_candidates = [t for t in val_universe if t not in key_set]\n",
    "                    if len(val_candidates) < n_pairs:\n",
    "                        raise ValueError(\"Not enough deterministic tokens for values after excluding keys.\")\n",
    "                    values_vocab = val_candidates[:n_pairs]\n",
    "            else:\n",
    "                # полностью случайные словари (не фиксированный универсум/порядок)\n",
    "                if keys_vocab is None:\n",
    "                    keys_vocab = random_tokens(\n",
    "                        need=n_pairs, charset=key_charset, length_range=key_token_len_range, avoid=reserved\n",
    "                    )\n",
    "                avoid_for_values = reserved | set(keys_vocab)\n",
    "                if values_vocab is None:\n",
    "                    values_vocab = random_tokens(\n",
    "                        need=n_pairs, charset=value_charset, length_range=value_token_len_range, avoid=avoid_for_values\n",
    "                    )\n",
    "\n",
    "        # финальные проверки\n",
    "        if set(keys_vocab) & set(values_vocab):\n",
    "            raise ValueError(\"keys_vocab and values_vocab must be disjoint.\")\n",
    "        if len(keys_vocab) < n_pairs or len(values_vocab) < n_pairs:\n",
    "            raise ValueError(\"Not enough tokens in keys_vocab/values_vocab for n_pairs.\")\n",
    "\n",
    "        self.keys_vocab = list(keys_vocab)\n",
    "        self.values_vocab = list(values_vocab)\n",
    "\n",
    "        # ---- строим env.vocab (пространство наблюдений/действий) ----\n",
    "        if deterministic_vocab and full_universe_vocab:\n",
    "            U_keys = det_tokens_for_range(key_token_len_range)\n",
    "            U_vals = det_tokens_for_range(value_token_len_range)\n",
    "            # объединяем в стабильном порядке: сначала U_keys, затем добавляем из U_vals всё, чего нет в U_keys\n",
    "            universe = U_keys + [t for t in U_vals if t not in set(U_keys)]\n",
    "            self.vocab = self.SPECIAL + universe\n",
    "        else:\n",
    "            # компактный словарь: только спец + выбранные ключи/значения\n",
    "            self.vocab = self.SPECIAL + self.keys_vocab + self.values_vocab\n",
    "\n",
    "        self.token_to_id = {tok: i for i, tok in enumerate(self.vocab)}\n",
    "        self.id_to_token = {i: tok for tok, i in self.token_to_id.items()}\n",
    "\n",
    "        # gym spaces\n",
    "        self.observation_space = spaces.Discrete(len(self.vocab))\n",
    "        self.action_space = spaces.Discrete(len(self.vocab))\n",
    "\n",
    "        # состояние эпизода\n",
    "        self._tokens: List[int] = []\n",
    "        self._ptr: int = 0\n",
    "        self._query_key: Optional[str] = None\n",
    "        self._mapping: Dict[str, str] = {}\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def _tok(self, s: str) -> int:\n",
    "        return self.token_to_id[s]\n",
    "\n",
    "    def _append_full_pair_tokens(self, stream: List[str], key: str):\n",
    "        \"\"\"Добавить токены полной пары: ! key : value !\"\"\"\n",
    "        stream += [\"!\", key, \":\", self._mapping[key], \"!\"]\n",
    "\n",
    "    def _build_after_pairs(self) -> List[str]:\n",
    "        # сэмплируем n_pairs уникальных ключей и значений из словарей-источников\n",
    "        keys = self.rng.sample(self.keys_vocab, self.n_pairs)\n",
    "        values = self.rng.sample(self.values_vocab, self.n_pairs)\n",
    "        self._mapping = {k: v for k, v in zip(keys, values)}\n",
    "\n",
    "        min_p, max_p = self.prefix_pairs_range\n",
    "        shown_pairs = self.rng.randint(min_p, max_p)\n",
    "        shown_order = self.rng.sample(keys, shown_pairs)\n",
    "\n",
    "        stream: List[str] = []\n",
    "        for k in shown_order:\n",
    "            self._append_full_pair_tokens(stream, k)\n",
    "\n",
    "        self._query_key = self.rng.choice(shown_order) if self.query_from_any_shown else shown_order[-1]\n",
    "        stream += [\"!\", self._query_key, \":\", \"shot\"]\n",
    "        return stream\n",
    "\n",
    "    def _build_after_any_colon(self) -> List[str]:\n",
    "        keys = self.rng.sample(self.keys_vocab, self.n_pairs)\n",
    "        values = self.rng.sample(self.values_vocab, self.n_pairs)\n",
    "        self._mapping = {k: v for k, v in zip(keys, values)}\n",
    "\n",
    "        min_p, max_p = self.prefix_pairs_range\n",
    "        min_p = max(1, min_p)  # нужен хотя бы один k:v, чтобы было что вспоминать\n",
    "        shown_pairs = self.rng.randint(min_p, max_p)\n",
    "\n",
    "        shown_order = self.rng.sample(keys, shown_pairs)\n",
    "\n",
    "        stream: List[str] = []\n",
    "        for k in shown_order:\n",
    "            self._append_full_pair_tokens(stream, k)\n",
    "\n",
    "        # ключ для запроса из показанных\n",
    "        self._query_key = self.rng.choice(shown_order) if self.query_from_any_shown else shown_order[-1]\n",
    "\n",
    "        # опциональные дополнительные пары перед повторным появлением ключа\n",
    "        remaining_keys = [k for k in keys if k not in shown_order]\n",
    "        extra_cap = min(self.max_extra_pairs_before_shot, len(remaining_keys))\n",
    "        extra_pairs = self.rng.randint(0, extra_cap)\n",
    "        self.rng.shuffle(remaining_keys)\n",
    "        for k in remaining_keys[:extra_pairs]:\n",
    "            self._append_full_pair_tokens(stream, k)\n",
    "\n",
    "        # повторный показ query_key, но вместо value → 'shot'\n",
    "        stream += [\"!\", self._query_key, \":\", \"shot\"]\n",
    "        return stream\n",
    "\n",
    "    def _build_episode(self):\n",
    "        if self.shot_mode == \"after_pairs\":\n",
    "            stream = self._build_after_pairs()\n",
    "        else:\n",
    "            stream = self._build_after_any_colon()\n",
    "        self._tokens = [self._tok(s) for s in stream]\n",
    "        self._ptr = 0\n",
    "\n",
    "    # ---------- Gym API ----------\n",
    "    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        if seed is not None:\n",
    "            self.rng.seed(seed)\n",
    "        self._build_episode()\n",
    "        obs = self._tokens[self._ptr]\n",
    "        info = {\n",
    "            \"mapping\": self._mapping.copy(),\n",
    "            \"query_key\": self._query_key,\n",
    "            \"vocab\": self.vocab,\n",
    "        }\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        assert 0 <= self._ptr < len(self._tokens), \"Episode finished. Call reset().\"\n",
    "\n",
    "        cur_tok_id = self._tokens[self._ptr]\n",
    "        cur_tok = self.id_to_token[cur_tok_id]\n",
    "\n",
    "        reward = 0.0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "\n",
    "        if cur_tok == \"shot\":\n",
    "            correct_value = self._mapping[self._query_key]\n",
    "            reward = 1.0 if action == self._tok(correct_value) else 0.0\n",
    "            terminated = True\n",
    "\n",
    "        self._ptr += 1\n",
    "        if self._ptr >= len(self._tokens):\n",
    "            terminated = True\n",
    "\n",
    "        obs = self._tok(\"pass\") if (terminated or truncated) else self._tokens[self._ptr]\n",
    "        info = {\n",
    "            \"query_key\": self._query_key,\n",
    "            \"correct_value\": self._mapping[self._query_key],\n",
    "            \"was_shot_step\": (cur_tok == \"shot\"),\n",
    "        }\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    # ---------- utils ----------\n",
    "    def decode_stream(self) -> List[str]:\n",
    "        return [self.id_to_token[t] for t in self._tokens]\n",
    "\n",
    "    def render(self):\n",
    "        print(\" \".join(self.decode_stream()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "85cd4c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 3848\n",
      "Obs.space: Discrete(3848)\n",
      "Action space: Discrete(3848)\n",
      "Query key: Ug\n",
      "Stream: ['!', 'Zb', ':', 'Bf', '!', '!', 'l7', ':', 'xv', '!', '!', 'H7', ':', 'de', '!', '!', 'TP', ':', '0t', '!', '!', '7l', ':', 'tO', '!', '!', '32', ':', '9R', '!', '!', 'GM', ':', 'KC', '!', '!', 'ZZ', ':', 'R7', '!', '!', 'iZ', ':', 'yJ', '!', '!', 'Ug', ':', 'lY', '!', '!', '0f', ':', 'lH', '!', '!', 'LN', ':', 'Z1', '!', '!', 'r4', ':', 'QR', '!', '!', 'OB', ':', 'JS', '!', '!', 'wa', ':', 'iD', '!', '!', '1Z', ':', '8z', '!', '!', 'U7', ':', 'th', '!', '!', 'Ev', ':', 'RE', '!', '!', 'BR', ':', 'JP', '!', '!', 'Ug', ':', 'shot']\n",
      "Stream: !Zb:Bf!!l7:xv!!H7:de!!TP:0t!!7l:tO!!32:9R!!GM:KC!!ZZ:R7!!iZ:yJ!!Ug:lY!!0f:lH!!LN:Z1!!r4:QR!!OB:JS!!wa:iD!!1Z:8z!!U7:th!!Ev:RE!!BR:JP!!Ug:shot\n",
      "Len stream: 99\n",
      "Total number of tokens: 99\n",
      "t=0   obs=0   token='!'\n",
      "t=1   obs=3797   token='Zb' \tact_tok='pass' \tr=0.0\n",
      "t=2   obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=3   obs=2313   token='Bf' \tact_tok='pass' \tr=0.0\n",
      "t=4   obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=5   obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=6   obs=1313   token='l7' \tact_tok='pass' \tr=0.0\n",
      "t=7   obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=8   obs=2081   token='xv' \tact_tok='pass' \tr=0.0\n",
      "t=9   obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=10  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=11  obs=2677   token='H7' \tact_tok='pass' \tr=0.0\n",
      "t=12  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=13  obs=824    token='de' \tact_tok='pass' \tr=0.0\n",
      "t=14  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=15  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=16  obs=3465   token='TP' \tact_tok='pass' \tr=0.0\n",
      "t=17  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=18  obs=33     token='0t' \tact_tok='pass' \tr=0.0\n",
      "t=19  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=20  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=21  obs=459    token='7l' \tact_tok='pass' \tr=0.0\n",
      "t=22  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=23  obs=1852   token='tO' \tact_tok='pass' \tr=0.0\n",
      "t=24  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=25  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=26  obs=192    token='32' \tact_tok='pass' \tr=0.0\n",
      "t=27  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=28  obs=615    token='9R' \tact_tok='pass' \tr=0.0\n",
      "t=29  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=30  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=31  obs=2656   token='GM' \tact_tok='pass' \tr=0.0\n",
      "t=32  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=33  obs=2894   token='KC' \tact_tok='pass' \tr=0.0\n",
      "t=34  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=35  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=36  obs=3847   token='ZZ' \tact_tok='pass' \tr=0.0\n",
      "t=37  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=38  obs=3297   token='R7' \tact_tok='pass' \tr=0.0\n",
      "t=39  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=40  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=41  obs=1181   token='iZ' \tact_tok='pass' \tr=0.0\n",
      "t=42  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=43  obs=2157   token='yJ' \tact_tok='pass' \tr=0.0\n",
      "t=44  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=45  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=46  obs=3492   token='Ug' \tact_tok='pass' \tr=0.0\n",
      "t=47  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=48  obs=1366   token='lY' \tact_tok='pass' \tr=0.0\n",
      "t=49  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=50  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=51  obs=19     token='0f' \tact_tok='pass' \tr=0.0\n",
      "t=52  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=53  obs=1349   token='lH' \tact_tok='pass' \tr=0.0\n",
      "t=54  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=55  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=56  obs=2967   token='LN' \tact_tok='pass' \tr=0.0\n",
      "t=57  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=58  obs=3787   token='Z1' \tact_tok='pass' \tr=0.0\n",
      "t=59  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=60  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=61  obs=1682   token='r4' \tact_tok='pass' \tr=0.0\n",
      "t=62  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=63  obs=3281   token='QR' \tact_tok='pass' \tr=0.0\n",
      "t=64  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=65  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=66  obs=3141   token='OB' \tact_tok='pass' \tr=0.0\n",
      "t=67  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=68  obs=2848   token='JS' \tact_tok='pass' \tr=0.0\n",
      "t=69  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=70  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=71  obs=1998   token='wa' \tact_tok='pass' \tr=0.0\n",
      "t=72  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=73  obs=1159   token='iD' \tact_tok='pass' \tr=0.0\n",
      "t=74  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=75  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=76  obs=127    token='1Z' \tact_tok='pass' \tr=0.0\n",
      "t=77  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=78  obs=535    token='8z' \tact_tok='pass' \tr=0.0\n",
      "t=79  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=80  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=81  obs=3483   token='U7' \tact_tok='pass' \tr=0.0\n",
      "t=82  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=83  obs=1819   token='th' \tact_tok='pass' \tr=0.0\n",
      "t=84  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=85  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=86  obs=2515   token='Ev' \tact_tok='pass' \tr=0.0\n",
      "t=87  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=88  obs=3330   token='RE' \tact_tok='pass' \tr=0.0\n",
      "t=89  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=90  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=91  obs=2351   token='BR' \tact_tok='pass' \tr=0.0\n",
      "t=92  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=93  obs=2845   token='JP' \tact_tok='pass' \tr=0.0\n",
      "t=94  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=95  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=96  obs=3492   token='Ug' \tact_tok='pass' \tr=0.0\n",
      "t=97  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=98  obs=2      token='shot' \tact_tok='pass' \tr=0.0\n",
      "t=99  obs=3      token='pass' \tact_tok='lY' \tr=1.0\n",
      "Reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "#  Размер словаря: 4 (SPECIAL: '!', ':', 'shot', 'eos') + 62*62 = 3848\n",
    "# (Если include_pass_token=True, будет 3849.\n",
    "env = ARShotEnv(\n",
    "    n_pairs=20, \n",
    "    rng_seed=None,\n",
    "    shot_mode=\"after_pairs\", # \"after_any_colon\" -> shot после любого ключа; \"after_pairs\" -> shot после последней пары\n",
    "    key_token_len_range=(2, 2),\n",
    "    value_token_len_range=(2, 2),\n",
    "    deterministic_vocab=True,\n",
    "    full_universe_vocab=True,    # <— ВАЖНО\n",
    "    randomize_pairs=True,          # ВАЖНО: пары выбираем случайно из универсума\n",
    "    include_pass_token=True\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "T = 5P+4 if shot_mode=\"after_pairs\"\n",
    "T = 5(P+E)+4 if shot_mode=\"after_any_colon\"\n",
    "\"\"\"\n",
    "\n",
    "obs, info = env.reset()\n",
    "print(\"Vocab size:\", env.observation_space.n)  # 4 спец + 80 keys + 80 values = 164\n",
    "print(\"Obs.space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Query key:\", info[\"query_key\"])\n",
    "print(\"Stream:\", env.decode_stream())\n",
    "print(\"Stream:\", \"\".join(env.decode_stream()))\n",
    "print(\"Len stream:\", len(env.decode_stream()))\n",
    "print(\"Total number of tokens:\", len(env.decode_stream()))\n",
    "\n",
    "done = False\n",
    "total = 0\n",
    "t = 0\n",
    "\n",
    "print(f\"t={t:<3} obs={obs:<3} token='{env.id_to_token[obs]}'\")\n",
    "while not done:\n",
    "    tok = env.id_to_token[obs]\n",
    "    if tok == \"shot\":\n",
    "        act_tok = info[\"mapping\"][info[\"query_key\"]]\n",
    "    else:\n",
    "        act_tok = \"pass\"\n",
    "    obs, r, done, _, _ = env.step(env.token_to_id[act_tok])\n",
    "    total += r\n",
    "    t += 1\n",
    "    obs_token = env.id_to_token[obs] if obs in env.id_to_token else \"pass\"\n",
    "    print(f\"t={t:<3} obs={obs:<6} token='{obs_token}' \\tact_tok='{act_tok}' \\tr={r}\")\n",
    "print(\"Reward:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e3c5c65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3848"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c59e7a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Zb': 'Bf',\n",
       " 'Ds': 'UB',\n",
       " 'H7': 'de',\n",
       " 'OB': 'JS',\n",
       " 'TP': '0t',\n",
       " '7l': 'tO',\n",
       " '1Z': '8z',\n",
       " 'LN': 'Z1',\n",
       " 'Ug': 'lY',\n",
       " 'Ev': 'RE',\n",
       " 'r4': 'QR',\n",
       " 'U7': 'th',\n",
       " 'BR': 'JP',\n",
       " '0f': 'lH',\n",
       " 'iZ': 'yJ',\n",
       " 'l7': 'xv',\n",
       " 'ZZ': 'R7',\n",
       " '32': '9R',\n",
       " 'wa': 'iD',\n",
       " 'GM': 'KC'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[\"mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e1e5ea8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OB',\n",
       " '1Z',\n",
       " 'Ds',\n",
       " 'wa',\n",
       " 'Zb',\n",
       " 'Ug',\n",
       " 'l7',\n",
       " 'GM',\n",
       " '7l',\n",
       " 'Ev',\n",
       " 'LN',\n",
       " 'U7',\n",
       " 'TP',\n",
       " '0f',\n",
       " 'H7',\n",
       " 'BR',\n",
       " 'r4',\n",
       " 'ZZ',\n",
       " '32',\n",
       " 'iZ']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.keys_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "20951045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "obs_id = env.token_to_id[\"pass\"]   # например 1287\n",
    "print(obs_id)\n",
    "tok = env.id_to_token[obs_id]    # вернёт \"zA\"\n",
    "print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008fc48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
