{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "359d576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gymnasium\n",
    "from __future__ import annotations\n",
    "import random\n",
    "import string\n",
    "from itertools import product\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class ARShotEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Associative Retrieval (AR) with a 'shot' query.\n",
    "\n",
    "    Поток токенов:\n",
    "      - shot_mode=\"after_pairs\":\n",
    "          [! k : v !] x P  +  [! query_key : shot]          → длина T = 5*P + 4\n",
    "      - shot_mode=\"after_any_colon\":\n",
    "          [! k : v !] x P  +  [! k : v !] x E + [! k : shot] → T = 5*(P+E) + 4\n",
    "        (query_key ранее уже встречался как полная пара)\n",
    "\n",
    "    Наблюдение — один токен за шаг.\n",
    "    Награда выдаётся только, когда текущий токен == 'shot':\n",
    "        reward = 1, если действие == правильному value; иначе 0. Эпизод завершается.\n",
    "\n",
    "    Важные флаги:\n",
    "      - deterministic_vocab=True  → порядок универсума фиксирован (не зависит от seed)\n",
    "      - full_universe_vocab=True → в env.vocab добавляется весь универсум токенов по длинам\n",
    "      - randomize_pairs=True     → ключи и значения для ЭПИЗОДА случайны (но из фикс. универсума)\n",
    "      - include_pass_token=True  → добавить 'pass' к спец-токенам (можно использовать как no-op)\n",
    "\n",
    "\n",
    "    # Отображение токенов в ID и обратно\n",
    "    obs_id = env.token_to_id[\"zA\"]   # например 1287\n",
    "    print(obs_id) # 1287\n",
    "    tok = env.id_to_token[obs_id]    # вернёт \"zA\"\n",
    "    print(tok) # \"zA\"\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": []}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_pairs: int = 6,\n",
    "        rng_seed: Optional[int] = None,\n",
    "\n",
    "        # где появится shot в смысле \"сколько полных пар точно показать сначала\"\n",
    "        prefix_pairs_range: Optional[Tuple[int, int]] = None,  # по умолчанию (1, n_pairs)\n",
    "        query_from_any_shown: bool = True,  # иначе берём последний из показанных\n",
    "\n",
    "        shot_mode: str = \"after_pairs\",  # \"after_pairs\" | \"after_any_colon\"\n",
    "        max_extra_pairs_before_shot: int = 0,  # только для \"after_any_colon\"\n",
    "\n",
    "        # словари (если None — берём из универсума согласно режимам ниже)\n",
    "        keys_vocab: Optional[List[str]] = None,\n",
    "        values_vocab: Optional[List[str]] = None,\n",
    "\n",
    "        # диапазоны длин токенов (включительно); чаще всего (2,2)\n",
    "        key_token_len_range: Tuple[int, int] = (2, 2),\n",
    "        value_token_len_range: Tuple[int, int] = (2, 2),\n",
    "\n",
    "        # алфавиты для НЕДЕТЕРМИНИРОВАННОЙ генерации\n",
    "        key_charset: str = string.ascii_letters + string.digits,\n",
    "        value_charset: str = string.ascii_letters + string.digits,\n",
    "\n",
    "        # управление словарём и его стабильностью\n",
    "        deterministic_vocab: bool = True,\n",
    "        full_universe_vocab: bool = True,\n",
    "        randomize_pairs: bool = True,\n",
    "        include_pass_token: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # RNG для динамики эпизодов и (опционально) случайного выбора пар\n",
    "        self.rng = random.Random(rng_seed)\n",
    "\n",
    "        # --- проверки параметров ---\n",
    "        assert n_pairs >= 1, \"n_pairs must be >= 1\"\n",
    "        if prefix_pairs_range is None:\n",
    "            prefix_pairs_range = (1, n_pairs)\n",
    "        min_p, max_p = prefix_pairs_range\n",
    "        if not (1 <= min_p <= max_p <= n_pairs):\n",
    "            raise ValueError(\"prefix_pairs_range must satisfy 1 <= min <= max <= n_pairs\")\n",
    "        if shot_mode not in (\"after_pairs\", \"after_any_colon\"):\n",
    "            raise ValueError(\"shot_mode must be 'after_pairs' or 'after_any_colon'\")\n",
    "\n",
    "        self.n_pairs = n_pairs\n",
    "        self.prefix_pairs_range = (min_p, max_p)\n",
    "        self.query_from_any_shown = query_from_any_shown\n",
    "        self.shot_mode = shot_mode\n",
    "        self.max_extra_pairs_before_shot = max(0, int(max_extra_pairs_before_shot))\n",
    "\n",
    "        # ---- SPECIAL tokens\n",
    "        self.SPECIAL = [\"!\", \":\", \"shot\", \"pass\"]\n",
    "        if include_pass_token:\n",
    "            self.SPECIAL.append(\"pass\")\n",
    "        reserved = set(self.SPECIAL)\n",
    "\n",
    "        # ---- детерминированный универсум токенов по диапазону длин\n",
    "        def det_tokens_for_range(length_range: Tuple[int, int]) -> List[str]:\n",
    "            \"\"\"\n",
    "            Генерирует все токены в лексикографическом порядке по фиксированному алфавиту:\n",
    "              digits + lowercase + uppercase = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "            Для длины L: перебор product(charset, repeat=L).\n",
    "            \"\"\"\n",
    "            lo, hi = length_range\n",
    "            if lo < 1 or hi < lo:\n",
    "                raise ValueError(\"length_range must satisfy 1 <= lo <= hi\")\n",
    "            charset = \"0123456789\" + string.ascii_lowercase + string.ascii_uppercase\n",
    "            out: List[str] = []\n",
    "            for L in range(lo, hi + 1):\n",
    "                for tup in product(charset, repeat=L):\n",
    "                    out.append(\"\".join(tup))\n",
    "            # спец-строк тут нет, но фильтр оставим\n",
    "            return [t for t in out if t not in reserved]\n",
    "\n",
    "        # ---- случайная генерация токенов (используется только если deterministic_vocab=False и словари не заданы)\n",
    "        def random_tokens(need: int, charset: str, length_range: Tuple[int, int], avoid: set[str]) -> List[str]:\n",
    "            lo, hi = length_range\n",
    "            if lo < 1 or hi < lo:\n",
    "                raise ValueError(\"length_range must satisfy 1 <= lo <= hi\")\n",
    "            tokens: List[str] = []\n",
    "            seen = set(avoid)\n",
    "            attempts = 0\n",
    "            while len(tokens) < need:\n",
    "                attempts += 1\n",
    "                L = self.rng.randint(lo, hi)\n",
    "                cand = \"\".join(self.rng.choice(charset) for _ in range(L))\n",
    "                if cand and cand not in seen:\n",
    "                    tokens.append(cand)\n",
    "                    seen.add(cand)\n",
    "                if attempts > 100_000:\n",
    "                    raise RuntimeError(\"Failed to generate enough unique random tokens; enlarge charset/lengths.\")\n",
    "            return tokens\n",
    "\n",
    "        # ---- строим словари источников для выбора пар в эпизодах (keys_vocab/values_vocab) ----\n",
    "        if keys_vocab is not None:\n",
    "            seen = set()\n",
    "            keys_vocab = [t for t in keys_vocab if (t not in reserved) and (t not in seen and not seen.add(t))]\n",
    "            if len(keys_vocab) < n_pairs:\n",
    "                raise ValueError(\"Provided keys_vocab has fewer unique tokens than n_pairs.\")\n",
    "        if values_vocab is not None:\n",
    "            seen = set()\n",
    "            values_vocab = [t for t in values_vocab if (t not in reserved) and (t not in seen and not seen.add(t))]\n",
    "\n",
    "        # если словари не заданы — берём из универсума согласно режимам\n",
    "        if keys_vocab is None or values_vocab is None:\n",
    "            if deterministic_vocab:\n",
    "                key_universe = det_tokens_for_range(key_token_len_range)\n",
    "                val_universe = det_tokens_for_range(value_token_len_range)\n",
    "\n",
    "                if randomize_pairs:\n",
    "                    # случайно выбираем пары (но из фиксированного универсума)\n",
    "                    if len(key_universe) < n_pairs:\n",
    "                        raise ValueError(\"Not enough deterministic tokens for keys.\")\n",
    "                    keys_vocab = self.rng.sample(key_universe, n_pairs)\n",
    "\n",
    "                    key_set = set(keys_vocab)\n",
    "                    val_candidates = [t for t in val_universe if t not in key_set]\n",
    "                    if len(val_candidates) < n_pairs:\n",
    "                        raise ValueError(\"Not enough deterministic tokens for values after excluding keys.\")\n",
    "                    values_vocab = self.rng.sample(val_candidates, n_pairs)\n",
    "                else:\n",
    "                    # берём первые n_pairs (фиксировано; пары не рандомизируются)\n",
    "                    if len(key_universe) < n_pairs:\n",
    "                        raise ValueError(\"Not enough deterministic tokens for keys.\")\n",
    "                    keys_vocab = key_universe[:n_pairs]\n",
    "\n",
    "                    key_set = set(keys_vocab)\n",
    "                    val_candidates = [t for t in val_universe if t not in key_set]\n",
    "                    if len(val_candidates) < n_pairs:\n",
    "                        raise ValueError(\"Not enough deterministic tokens for values after excluding keys.\")\n",
    "                    values_vocab = val_candidates[:n_pairs]\n",
    "            else:\n",
    "                # полностью случайные словари (не фиксированный универсум/порядок)\n",
    "                if keys_vocab is None:\n",
    "                    keys_vocab = random_tokens(\n",
    "                        need=n_pairs, charset=key_charset, length_range=key_token_len_range, avoid=reserved\n",
    "                    )\n",
    "                avoid_for_values = reserved | set(keys_vocab)\n",
    "                if values_vocab is None:\n",
    "                    values_vocab = random_tokens(\n",
    "                        need=n_pairs, charset=value_charset, length_range=value_token_len_range, avoid=avoid_for_values\n",
    "                    )\n",
    "\n",
    "        # финальные проверки\n",
    "        if set(keys_vocab) & set(values_vocab):\n",
    "            raise ValueError(\"keys_vocab and values_vocab must be disjoint.\")\n",
    "        if len(keys_vocab) < n_pairs or len(values_vocab) < n_pairs:\n",
    "            raise ValueError(\"Not enough tokens in keys_vocab/values_vocab for n_pairs.\")\n",
    "\n",
    "        self.keys_vocab = list(keys_vocab)\n",
    "        self.values_vocab = list(values_vocab)\n",
    "\n",
    "        # ---- строим env.vocab (пространство наблюдений/действий) ----\n",
    "        if deterministic_vocab and full_universe_vocab:\n",
    "            U_keys = det_tokens_for_range(key_token_len_range)\n",
    "            U_vals = det_tokens_for_range(value_token_len_range)\n",
    "            # объединяем в стабильном порядке: сначала U_keys, затем добавляем из U_vals всё, чего нет в U_keys\n",
    "            universe = U_keys + [t for t in U_vals if t not in set(U_keys)]\n",
    "            self.vocab = self.SPECIAL + universe\n",
    "        else:\n",
    "            # компактный словарь: только спец + выбранные ключи/значения\n",
    "            self.vocab = self.SPECIAL + self.keys_vocab + self.values_vocab\n",
    "\n",
    "        self.token_to_id = {tok: i for i, tok in enumerate(self.vocab)}\n",
    "        self.id_to_token = {i: tok for tok, i in self.token_to_id.items()}\n",
    "\n",
    "        # gym spaces\n",
    "        self.observation_space = spaces.Discrete(len(self.vocab))\n",
    "        self.action_space = spaces.Discrete(len(self.vocab))\n",
    "\n",
    "        # состояние эпизода\n",
    "        self._tokens: List[int] = []\n",
    "        self._ptr: int = 0\n",
    "        self._query_key: Optional[str] = None\n",
    "        self._mapping: Dict[str, str] = {}\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def _tok(self, s: str) -> int:\n",
    "        return self.token_to_id[s]\n",
    "\n",
    "    def _append_full_pair_tokens(self, stream: List[str], key: str):\n",
    "        \"\"\"Добавить токены полной пары: ! key : value !\"\"\"\n",
    "        stream += [\"!\", key, \":\", self._mapping[key], \"!\"]\n",
    "\n",
    "    def _build_after_pairs(self) -> List[str]:\n",
    "        # сэмплируем n_pairs уникальных ключей и значений из словарей-источников\n",
    "        keys = self.rng.sample(self.keys_vocab, self.n_pairs)\n",
    "        values = self.rng.sample(self.values_vocab, self.n_pairs)\n",
    "        self._mapping = {k: v for k, v in zip(keys, values)}\n",
    "\n",
    "        min_p, max_p = self.prefix_pairs_range\n",
    "        shown_pairs = self.rng.randint(min_p, max_p)\n",
    "        shown_order = self.rng.sample(keys, shown_pairs)\n",
    "\n",
    "        stream: List[str] = []\n",
    "        for k in shown_order:\n",
    "            self._append_full_pair_tokens(stream, k)\n",
    "\n",
    "        self._query_key = self.rng.choice(shown_order) if self.query_from_any_shown else shown_order[-1]\n",
    "        stream += [\"!\", self._query_key, \":\", \"shot\"]\n",
    "        return stream\n",
    "\n",
    "    def _build_after_any_colon(self) -> List[str]:\n",
    "        keys = self.rng.sample(self.keys_vocab, self.n_pairs)\n",
    "        values = self.rng.sample(self.values_vocab, self.n_pairs)\n",
    "        self._mapping = {k: v for k, v in zip(keys, values)}\n",
    "\n",
    "        min_p, max_p = self.prefix_pairs_range\n",
    "        min_p = max(1, min_p)  # нужен хотя бы один k:v, чтобы было что вспоминать\n",
    "        shown_pairs = self.rng.randint(min_p, max_p)\n",
    "\n",
    "        shown_order = self.rng.sample(keys, shown_pairs)\n",
    "\n",
    "        stream: List[str] = []\n",
    "        for k in shown_order:\n",
    "            self._append_full_pair_tokens(stream, k)\n",
    "\n",
    "        # ключ для запроса из показанных\n",
    "        self._query_key = self.rng.choice(shown_order) if self.query_from_any_shown else shown_order[-1]\n",
    "\n",
    "        # опциональные дополнительные пары перед повторным появлением ключа\n",
    "        remaining_keys = [k for k in keys if k not in shown_order]\n",
    "        extra_cap = min(self.max_extra_pairs_before_shot, len(remaining_keys))\n",
    "        extra_pairs = self.rng.randint(0, extra_cap)\n",
    "        self.rng.shuffle(remaining_keys)\n",
    "        for k in remaining_keys[:extra_pairs]:\n",
    "            self._append_full_pair_tokens(stream, k)\n",
    "\n",
    "        # повторный показ query_key, но вместо value → 'shot'\n",
    "        stream += [\"!\", self._query_key, \":\", \"shot\"]\n",
    "        return stream\n",
    "\n",
    "    def _build_episode(self):\n",
    "        if self.shot_mode == \"after_pairs\":\n",
    "            stream = self._build_after_pairs()\n",
    "        else:\n",
    "            stream = self._build_after_any_colon()\n",
    "        self._tokens = [self._tok(s) for s in stream]\n",
    "        self._ptr = 0\n",
    "\n",
    "    # ---------- Gym API ----------\n",
    "    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        if seed is not None:\n",
    "            self.rng.seed(seed)\n",
    "        self._build_episode()\n",
    "        obs = self._tokens[self._ptr]\n",
    "        info = {\n",
    "            \"mapping\": self._mapping.copy(),\n",
    "            \"query_key\": self._query_key,\n",
    "            \"vocab\": self.vocab,\n",
    "        }\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        assert 0 <= self._ptr < len(self._tokens), \"Episode finished. Call reset().\"\n",
    "\n",
    "        cur_tok_id = self._tokens[self._ptr]\n",
    "        cur_tok = self.id_to_token[cur_tok_id]\n",
    "\n",
    "        reward = 0.0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "\n",
    "        if cur_tok == \"shot\":\n",
    "            correct_value = self._mapping[self._query_key]\n",
    "            reward = 1.0 if action == self._tok(correct_value) else 0.0\n",
    "            terminated = True\n",
    "\n",
    "        self._ptr += 1\n",
    "        if self._ptr >= len(self._tokens):\n",
    "            terminated = True\n",
    "\n",
    "        obs = self._tok(\"pass\") if (terminated or truncated) else self._tokens[self._ptr]\n",
    "        info = {\n",
    "            \"query_key\": self._query_key,\n",
    "            \"correct_value\": self._mapping[self._query_key],\n",
    "            \"was_shot_step\": (cur_tok == \"shot\"),\n",
    "        }\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    # ---------- utils ----------\n",
    "    def decode_stream(self) -> List[str]:\n",
    "        return [self.id_to_token[t] for t in self._tokens]\n",
    "\n",
    "    def render(self):\n",
    "        print(\" \".join(self.decode_stream()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "85cd4c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 3849\n",
      "Obs.space: Discrete(3849)\n",
      "Action space: Discrete(3849)\n",
      "Query key: jZ\n",
      "Stream: ['!', 'R4', ':', 'Ba', '!', '!', 'zH', ':', 'kR', '!', '!', '3L', ':', 'dX', '!', '!', 'Wi', ':', 'gL', '!', '!', 'CK', ':', 'Nd', '!', '!', 'b8', ':', '0A', '!', '!', 'xw', ':', 'Uj', '!', '!', 'jZ', ':', 'EN', '!', '!', 'QJ', ':', 'cL', '!', '!', 'wX', ':', 'Bt', '!', '!', 'Np', ':', 'Cb', '!', '!', 'zN', ':', 'vI', '!', '!', 'PO', ':', '6u', '!', '!', 'DD', ':', 'hZ', '!', '!', 'jZ', ':', 'shot']\n",
      "Stream: !R4:Ba!!zH:kR!!3L:dX!!Wi:gL!!CK:Nd!!b8:0A!!xw:Uj!!jZ:EN!!QJ:cL!!wX:Bt!!Np:Cb!!zN:vI!!PO:6u!!DD:hZ!!jZ:shot\n",
      "Len stream: 74\n",
      "Total number of tokens: 74\n",
      "t=0   obs=0   token='!'\n",
      "t=1   obs=3295   token='R4' \tact_tok='pass' \tr=0.0\n",
      "t=2   obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=3   obs=2309   token='Ba' \tact_tok='pass' \tr=0.0\n",
      "t=4   obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=5   obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=6   obs=2218   token='zH' \tact_tok='pass' \tr=0.0\n",
      "t=7   obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=8   obs=1298   token='kR' \tact_tok='pass' \tr=0.0\n",
      "t=9   obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=10  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=11  obs=238    token='3L' \tact_tok='pass' \tr=0.0\n",
      "t=12  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=13  obs=870    token='dX' \tact_tok='pass' \tr=0.0\n",
      "t=14  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=15  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=16  obs=3619   token='Wi' \tact_tok='pass' \tr=0.0\n",
      "t=17  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=18  obs=1044   token='gL' \tact_tok='pass' \tr=0.0\n",
      "t=19  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=20  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=21  obs=2407   token='CK' \tact_tok='pass' \tr=0.0\n",
      "t=22  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=23  obs=3056   token='Nd' \tact_tok='pass' \tr=0.0\n",
      "t=24  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=25  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=26  obs=695    token='b8' \tact_tok='pass' \tr=0.0\n",
      "t=27  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=28  obs=41     token='0A' \tact_tok='pass' \tr=0.0\n",
      "t=29  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=30  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=31  obs=2083   token='xw' \tact_tok='pass' \tr=0.0\n",
      "t=32  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=33  obs=3496   token='Uj' \tact_tok='pass' \tr=0.0\n",
      "t=34  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=35  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=36  obs=1244   token='jZ' \tact_tok='pass' \tr=0.0\n",
      "t=37  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=38  obs=2534   token='EN' \tact_tok='pass' \tr=0.0\n",
      "t=39  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=40  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=41  obs=3274   token='QJ' \tact_tok='pass' \tr=0.0\n",
      "t=42  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=43  obs=796    token='cL' \tact_tok='pass' \tr=0.0\n",
      "t=44  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=45  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=46  obs=2048   token='wX' \tact_tok='pass' \tr=0.0\n",
      "t=47  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=48  obs=2328   token='Bt' \tact_tok='pass' \tr=0.0\n",
      "t=49  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=50  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=51  obs=3068   token='Np' \tact_tok='pass' \tr=0.0\n",
      "t=52  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=53  obs=2372   token='Cb' \tact_tok='pass' \tr=0.0\n",
      "t=54  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=55  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=56  obs=2224   token='zN' \tact_tok='pass' \tr=0.0\n",
      "t=57  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=58  obs=1971   token='vI' \tact_tok='pass' \tr=0.0\n",
      "t=59  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=60  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=61  obs=3217   token='PO' \tact_tok='pass' \tr=0.0\n",
      "t=62  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=63  obs=407    token='6u' \tact_tok='pass' \tr=0.0\n",
      "t=64  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=65  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=66  obs=2462   token='DD' \tact_tok='pass' \tr=0.0\n",
      "t=67  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=68  obs=1120   token='hZ' \tact_tok='pass' \tr=0.0\n",
      "t=69  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=70  obs=0      token='!' \tact_tok='pass' \tr=0.0\n",
      "t=71  obs=1244   token='jZ' \tact_tok='pass' \tr=0.0\n",
      "t=72  obs=1      token=':' \tact_tok='pass' \tr=0.0\n",
      "t=73  obs=2      token='shot' \tact_tok='pass' \tr=0.0\n",
      "t=74  obs=4      token='pass' \tact_tok='EN' \tr=1.0\n",
      "Reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "#  Размер словаря: 4 (SPECIAL: '!', ':', 'shot', 'eos') + 62*62 = 3848\n",
    "# (Если include_pass_token=True, будет 3849.\n",
    "env = ARShotEnv(\n",
    "    n_pairs=20, \n",
    "    rng_seed=None,\n",
    "    shot_mode=\"after_pairs\", # \"after_any_colon\" -> shot после любого ключа; \"after_pairs\" -> shot после последней пары\n",
    "    key_token_len_range=(2, 2),\n",
    "    value_token_len_range=(2, 2),\n",
    "    deterministic_vocab=True,\n",
    "    full_universe_vocab=True,    # <— ВАЖНО\n",
    "    randomize_pairs=True,          # ВАЖНО: пары выбираем случайно из универсума\n",
    "    include_pass_token=True\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "T = 5P+4 if shot_mode=\"after_pairs\"\n",
    "T = 5(P+E)+4 if shot_mode=\"after_any_colon\"\n",
    "\"\"\"\n",
    "\n",
    "obs, info = env.reset()\n",
    "print(\"Vocab size:\", env.observation_space.n)  # 4 спец + 80 keys + 80 values = 164\n",
    "print(\"Obs.space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Query key:\", info[\"query_key\"])\n",
    "print(\"Stream:\", env.decode_stream())\n",
    "print(\"Stream:\", \"\".join(env.decode_stream()))\n",
    "print(\"Len stream:\", len(env.decode_stream()))\n",
    "print(\"Total number of tokens:\", len(env.decode_stream()))\n",
    "\n",
    "done = False\n",
    "total = 0\n",
    "t = 0\n",
    "\n",
    "print(f\"t={t:<3} obs={obs:<3} token='{env.id_to_token[obs]}'\")\n",
    "while not done:\n",
    "    tok = env.id_to_token[obs]\n",
    "    if tok == \"shot\":\n",
    "        act_tok = info[\"mapping\"][info[\"query_key\"]]\n",
    "    else:\n",
    "        act_tok = \"pass\"\n",
    "    obs, r, done, _, _ = env.step(env.token_to_id[act_tok])\n",
    "    total += r\n",
    "    t += 1\n",
    "    obs_token = env.id_to_token[obs] if obs in env.id_to_token else \"pass\"\n",
    "    print(f\"t={t:<3} obs={obs:<6} token='{obs_token}' \\tact_tok='{act_tok}' \\tr={r}\")\n",
    "print(\"Reward:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3c5c65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3849"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c59e7a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qY': '9O',\n",
       " 'Am': 'eL',\n",
       " 'V4': 'OB',\n",
       " 'uo': 'eG',\n",
       " '2v': 'pa',\n",
       " 'Hk': 'My',\n",
       " 'VR': '5L',\n",
       " 'OO': 'q4',\n",
       " 'E6': 'Eo',\n",
       " 'fF': 'Tq',\n",
       " '0g': 'sf',\n",
       " 'fs': 'KI',\n",
       " 'VJ': 'D2',\n",
       " 'zl': '6Y',\n",
       " '5Z': 'Kv',\n",
       " 'iz': 'Fm',\n",
       " '41': '88',\n",
       " 'ZR': 'bd',\n",
       " 'AO': '3n',\n",
       " 'gp': 's0'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[\"mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1e5ea8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E6',\n",
       " 'zl',\n",
       " 'iz',\n",
       " '2v',\n",
       " 'VJ',\n",
       " '41',\n",
       " 'Hk',\n",
       " 'ZR',\n",
       " 'VR',\n",
       " 'uo',\n",
       " 'gp',\n",
       " 'OO',\n",
       " 'qY',\n",
       " 'V4',\n",
       " '0g',\n",
       " 'Am',\n",
       " 'fF',\n",
       " 'AO',\n",
       " '5Z',\n",
       " 'fs']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.keys_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "20951045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "obs_id = env.token_to_id[\"pass\"]   # например 1287\n",
    "print(obs_id)\n",
    "tok = env.id_to_token[obs_id]    # вернёт \"zA\"\n",
    "print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008fc48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
