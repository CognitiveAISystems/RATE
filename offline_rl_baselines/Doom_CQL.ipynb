{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddef2d4d-e9f8-43e3-b5c1-312f6c33af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import wandb\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import argparse\n",
    "import yaml\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "sys.path.append('../')\n",
    "from VizDoom.VizDoom_src.utils import get_vizdoom_iter_dataset, ViZDoomIterDataset\n",
    "from VizDoom.VizDoom_src.train import trainer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "#import env_vizdoom2\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count\n",
    "import time\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9165015-4dd0-4a31-af49-af320a1a42b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length=90\n"
     ]
    }
   ],
   "source": [
    "with open(\"../VizDoom/VizDoom_src/config.yaml\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "config[\"training_config\"][\"batch_size\"] = 128\n",
    "max_length = config[\"training_config\"][\"sections\"]*config[\"training_config\"][\"context_length\"]\n",
    "print(f\"{max_length=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb8341c-300f-4a10-8ac1-855fc463b8c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from lstm_agent_cql import DecisionLSTM\n",
    "\n",
    "agent = DecisionLSTM(4, 1, 128, mode='doom')\n",
    "\n",
    "# PATH = f'DOOM_BC_270_sar'\n",
    "# weights = torch.load(f\"{PATH}.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "# agent.load_state_dict(weights, strict=True)\n",
    "agent.train()\n",
    "agent.to(agent.device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(agent.parameters(), lr=config[\"training_config\"][\"learning_rate\"], \n",
    "                                      weight_decay=config[\"training_config\"][\"weight_decay\"], \n",
    "                                      betas=(config[\"training_config\"][\"beta_1\"], config[\"training_config\"][\"beta_2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9119635-da20-462e-9e21-0d13aa88ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:27<00:00, 184.58it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_splitted_dataset = '../../../RATE/VizDoom/VizDoom_data/iterative_data/'\n",
    "train_dataset = ViZDoomIterDataset(path_to_splitted_dataset, \n",
    "                                 gamma=config[\"data_config\"][\"gamma\"], \n",
    "                                 max_length=max_length, \n",
    "                                 normalize=config[\"data_config\"][\"normalize\"])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                             batch_size=config[\"training_config\"][\"batch_size\"],\n",
    "                             shuffle=True, \n",
    "                             num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e939cb4-f31c-41ac-a8a5-936cbe5c4f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcherepanovegor2018\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/Egor_C/REPOSITORIES/rate_maniskill/RATE/offline_rl_baselines/wandb/run-20241215_224853-c10o6a4n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cherepanovegor2018/RATE_DOOM_CQL/runs/c10o6a4n' target=\"_blank\">doom_cql_sar</a></strong> to <a href='https://wandb.ai/cherepanovegor2018/RATE_DOOM_CQL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cherepanovegor2018/RATE_DOOM_CQL' target=\"_blank\">https://wandb.ai/cherepanovegor2018/RATE_DOOM_CQL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cherepanovegor2018/RATE_DOOM_CQL/runs/c10o6a4n' target=\"_blank\">https://wandb.ai/cherepanovegor2018/RATE_DOOM_CQL/runs/c10o6a4n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/cherepanovegor2018/RATE_DOOM_CQL/runs/c10o6a4n?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fac0c4937d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../wandb_config.yaml\") as f:\n",
    "    wandb_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "os.environ['WANDB_API_KEY'] = wandb_config['wandb_api']\n",
    "\n",
    "# os.environ['WANDB_API_KEY'] = 'WANDB_API_KEY'\n",
    "EXP_NAME = 'doom_cql_sar'\n",
    "wandb.init(project=\"RATE_DOOM_CQL\", name=f'{EXP_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18ec4404-c41c-4e71-9ae0-a0143dfd7625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0 It: 38 Train Loss: 14.58031177520752 (BC: 0.8446, Q1: 2.7800, Q2: 2.2558, CQL: 8.7000)\n",
      "Epochs: 1 It: 38 Train Loss: 11.613214492797852 (BC: 0.7044, Q1: 0.9505, Q2: 0.9202, CQL: 9.0381)\n",
      "Epochs: 2 It: 38 Train Loss: 10.923055648803711 (BC: 0.6561, Q1: 0.7344, Q2: 0.7383, CQL: 8.7943)\n",
      "Epochs: 3 It: 38 Train Loss: 10.676511764526367 (BC: 0.6502, Q1: 0.6661, Q2: 0.6743, CQL: 8.6859)\n",
      "Epochs: 4 It: 38 Train Loss: 10.935297012329102 (BC: 0.6430, Q1: 0.8107, Q2: 0.8106, CQL: 8.6710)\n",
      "Epochs: 5 It: 38 Train Loss: 10.791973114013672 (BC: 0.6394, Q1: 0.7971, Q2: 0.7980, CQL: 8.5574)\n",
      "Epochs: 6 It: 38 Train Loss: 10.514238357543945 (BC: 0.6417, Q1: 0.7139, Q2: 0.7052, CQL: 8.4534)\n",
      "Epochs: 7 It: 38 Train Loss: 10.358912467956543 (BC: 0.6402, Q1: 0.6507, Q2: 0.6335, CQL: 8.4345)\n",
      "Epochs: 8 It: 38 Train Loss: 10.652642250061035 (BC: 0.6365, Q1: 0.7632, Q2: 0.7652, CQL: 8.4877)\n",
      "Epochs: 9 It: 38 Train Loss: 10.682952880859375 (BC: 0.6421, Q1: 0.7503, Q2: 0.7431, CQL: 8.5474)\n",
      "Epochs: 10 It: 38 Train Loss: 10.507163047790527 (BC: 0.6318, Q1: 0.8294, Q2: 0.7945, CQL: 8.2514)\n",
      "Epochs: 11 It: 38 Train Loss: 10.313529968261719 (BC: 0.6293, Q1: 0.6714, Q2: 0.6609, CQL: 8.3519)\n",
      "Epochs: 12 It: 38 Train Loss: 10.31074047088623 (BC: 0.6324, Q1: 0.7131, Q2: 0.7014, CQL: 8.2638)\n",
      "Epochs: 13 It: 38 Train Loss: 10.01968002319336 (BC: 0.6315, Q1: 0.5643, Q2: 0.5588, CQL: 8.2650)\n",
      "Epochs: 14 It: 38 Train Loss: 10.190017700195312 (BC: 0.6343, Q1: 0.7301, Q2: 0.7146, CQL: 8.1111)\n",
      "Epochs: 15 It: 38 Train Loss: 10.163579940795898 (BC: 0.6349, Q1: 0.7492, Q2: 0.7031, CQL: 8.0764)\n",
      "Epochs: 16 It: 38 Train Loss: 9.818747520446777 (BC: 0.6299, Q1: 0.5474, Q2: 0.5539, CQL: 8.0876)\n",
      "Epochs: 17 It: 38 Train Loss: 9.838618278503418 (BC: 0.6382, Q1: 0.5243, Q2: 0.5256, CQL: 8.1506)\n",
      "Epochs: 18 It: 38 Train Loss: 9.87350082397461 (BC: 0.6366, Q1: 0.5546, Q2: 0.5576, CQL: 8.1246)\n",
      "Epochs: 19 It: 38 Train Loss: 9.821958541870117 (BC: 0.6274, Q1: 0.5746, Q2: 0.5473, CQL: 8.0727)\n",
      "Epochs: 20 It: 38 Train Loss: 9.761300086975098 (BC: 0.6234, Q1: 0.5156, Q2: 0.5092, CQL: 8.1131)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m s, a, rtg, d, timesteps, masks \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     24\u001b[0m d[d\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\n\u001b[0;32m---> 25\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43md\u001b[49m\n\u001b[1;32m     26\u001b[0m d \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     27\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/.mlspace/envs/BERSERK/lib/python3.11/site-packages/torch/_tensor.py:34\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m(f):\n\u001b[1;32m     32\u001b[0m     assigned \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion_all = nn.CrossEntropyLoss(ignore_index=-10, reduction='mean')\n",
    "agent.train()\n",
    "\n",
    "CQL_ALPHA = 1.0\n",
    "DISCOUNT = 0.99\n",
    "#TARGET_UPDATE_FREQ = 10\n",
    "TAU = 0.005  # Soft update parameter\n",
    "TARGET_UPDATE_FREQ = 10\n",
    "\n",
    "target_q1 = copy.deepcopy(agent.q1)\n",
    "target_q2 = copy.deepcopy(agent.q2)\n",
    "\n",
    "for param in target_q1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in target_q2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for epochs in range(3600):\n",
    "    \n",
    "    agent.train()\n",
    "    \n",
    "    for it, batch in enumerate(train_dataloader):\n",
    "        s, a, rtg, d, timesteps, masks = batch\n",
    "        d[d==2] = 1.\n",
    "        d = 1-d\n",
    "        d = d.unsqueeze(-1).cuda()\n",
    "        s = s.cuda()\n",
    "        a = a.cuda()\n",
    "        rtg = rtg.cuda().float()\n",
    "\n",
    "        agent.init_hidden(s.shape[0])\n",
    "\n",
    "        action_preds, q1_pred, q2_pred, cql_loss = agent(s,a,rtg, stacked_input=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_s = s[:, 1:]\n",
    "            next_a = a[:, 1:]\n",
    "            next_rtg = rtg[:, 1:]\n",
    "\n",
    "            _, next_q1, next_q2, _ = agent(next_s, next_a, next_rtg, stacked_input=True)\n",
    "            next_q = torch.min(next_q1, next_q2)\n",
    "            target_q = rtg[:, :-1] + DISCOUNT * (1 - d[:, :-1]) * next_q\n",
    "\n",
    "        q1_loss = F.mse_loss(q1_pred[:, :-1], target_q)\n",
    "        q2_loss = F.mse_loss(q2_pred[:, :-1], target_q)   \n",
    "\n",
    "    #     break\n",
    "    # break\n",
    "    \n",
    "        action_preds = action_preds.reshape(-1, action_preds.size(-1))\n",
    "        target_actions = a.reshape(-1).long()\n",
    "        bc_loss = criterion_all(action_preds, target_actions)\n",
    "        \n",
    "        total_loss = q1_loss + q2_loss + cql_loss + bc_loss\n",
    "        #total_loss = bc_loss\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()#retain_graph=False)\n",
    "        torch.nn.utils.clip_grad_norm_(agent.parameters(), config[\"training_config\"][\"grad_norm_clip\"])\n",
    "        optimizer.step()\n",
    "    \n",
    "    if it % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            for param, target_param in zip(agent.q1.parameters(), target_q1.parameters()):\n",
    "                target_param.data.copy_(TAU * param.data + (1 - TAU) * target_param.data)\n",
    "            for param, target_param in zip(agent.q2.parameters(), target_q2.parameters()):\n",
    "                target_param.data.copy_(TAU * param.data + (1 - TAU) * target_param.data)\n",
    "        \n",
    "    print(f'Epochs: {epochs} It: {it} Train Loss: {total_loss.item()} '\n",
    "          f'(BC: {bc_loss.item():.4f}, Q1: {q1_loss.item():.4f}, '\n",
    "          f'Q2: {q2_loss.item():.4f}, CQL: {cql_loss.item():.4f})')\n",
    "\n",
    "    wandb.log({'BC':bc_loss.item()})\n",
    "    wandb.log({'Q1':q1_loss.item()})\n",
    "    wandb.log({'Q2':q2_loss.item()})\n",
    "    wandb.log({'CQL':cql_loss.item()})\n",
    "\n",
    "\n",
    "    if epochs%10==0:\n",
    "        PATH = f'./ckpt/Doom_lstm_SAR_90_CQL'\n",
    "        os.makedirs(PATH, exist_ok=True)\n",
    "        torch.save(agent.state_dict(),f\"{PATH}.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f640963-c27e-4ece-b08a-741269d31c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db24fc56-23d1-4faa-af1d-479d92607076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c308c34-1a37-4ffa-892c-45fbd35dbe85",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70aa8227-f559-42a1-a147-9550e1364e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../VizDoom/VizDoom_notebooks/')\n",
    "from VizDoom.VizDoom_notebooks.doom_environment2 import DoomEnvironment\n",
    "import env_vizdoom2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf6eb8e0-c277-44d0-bd0e-d891e9763e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_args = {\n",
    "    'simulator':'doom', \n",
    "    'scenario':'custom_scenario{:003}.cfg', #custom_scenario_no_pil{:003}.cfg\n",
    "    'test_scenario':'', \n",
    "    'screen_size':'320X180', \n",
    "    'screen_height':64, \n",
    "    'screen_width':112, \n",
    "    'num_environments':16,# 16\n",
    "    'limit_actions':True, \n",
    "    'scenario_dir':'../VizDoom/VizDoom_src/env/',\n",
    "    'test_scenario_dir':'', \n",
    "    'show_window':False, \n",
    "    'resize':True, \n",
    "    'multimaze':True, \n",
    "    'num_mazes_train':16, \n",
    "    'num_mazes_test':1, # 64 \n",
    "    'disable_head_bob':False, \n",
    "    'use_shaping':False, \n",
    "    'fixed_scenario':False, \n",
    "    'use_pipes':False, \n",
    "    'num_actions':0, \n",
    "    'hidden_size':128, \n",
    "    'reload_model':'', \n",
    "    'model_checkpoint':'./VizDoom/VizDoom_notebooks/two_col_p1_checkpoint_0198658048.pth.tar',   # two_col_p0_checkpoint_0049154048.pth.tar',  #two_col_p0_checkpoint_0198658048.pth.tar', \n",
    "    'conv1_size':16, \n",
    "    'conv2_size':32, \n",
    "    'conv3_size':16, \n",
    "    'learning_rate':0.0007, \n",
    "    'momentum':0.0, \n",
    "    'gamma':0.99, \n",
    "    'frame_skip':4, \n",
    "    'train_freq':4, \n",
    "    'train_report_freq':100, \n",
    "    'max_iters':5000000, \n",
    "    'eval_freq':1000, \n",
    "    'eval_games':50, \n",
    "    'model_save_rate':1000, \n",
    "    'eps':1e-05, \n",
    "    'alpha':0.99, \n",
    "    'use_gae':False, \n",
    "    'tau':0.95, \n",
    "    'entropy_coef':0.001, \n",
    "    'value_loss_coef':0.5, \n",
    "    'max_grad_norm':0.5, \n",
    "    'num_steps':128, \n",
    "    'num_stack':1, \n",
    "    'num_frames':200000000, \n",
    "    'use_em_loss':False, \n",
    "    'skip_eval':False, \n",
    "    'stoc_evals':False, \n",
    "    'model_dir':'', \n",
    "    'out_dir':'./', \n",
    "    'log_interval':100, \n",
    "    'job_id':12345, \n",
    "    'test_name':'test_000', \n",
    "    'use_visdom':False, \n",
    "    'visdom_port':8097, \n",
    "    'visdom_ip':'http://10.0.0.1'                 \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d75602e2-8b8c-41c7-bf52-301563799f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = 0\n",
    "scenario = env_args['scenario_dir'] + env_args['scenario'].format(scene) # 0 % 63\n",
    "config = scenario\n",
    "device = 'cuda:0'\n",
    "\n",
    "env = env_vizdoom2.DoomEnvironmentDisappear(\n",
    "    scenario=config,\n",
    "    show_window=False,\n",
    "    use_info=True,\n",
    "    use_shaping=False, #if False bonus reward if #shaping reward is always: +1,-1 in two_towers\n",
    "    frame_skip=2,\n",
    "    no_backward_movement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fbe6fa7-fa79-411a-b8c1-57fdae84644b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionLSTM(\n",
       "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True)\n",
       "  (predict_action): Linear(in_features=128, out_features=5, bias=False)\n",
       "  (embed_state): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    (7): Linear(in_features=2560, out_features=128, bias=True)\n",
       "    (8): Tanh()\n",
       "  )\n",
       "  (embed_action_toq): Sequential(\n",
       "    (0): Embedding(5, 5)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (embed_action): Sequential(\n",
       "    (0): Embedding(5, 128)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (embed_return): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (q1): Sequential(\n",
       "    (0): Linear(in_features=129, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (q2): Sequential(\n",
       "    (0): Linear(in_features=129, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PATH = f'Doom_lstm_S_90_CQL'\n",
    "PATH = f'ckpt/1/Doom_lstm_SAR_90_CQL'\n",
    "# PATH = f'Doom_lstm_SAR_90_CQL'\n",
    "\n",
    "weights = torch.load(f\"{PATH}.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "agent.load_state_dict(weights, strict=True)\n",
    "agent.train()\n",
    "agent.to(agent.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d5f92af-9ff6-4ca0-aade-7bcdcd393b10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:50<00:00,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "EPISODE_TIMEOUT = 4200 # 90\n",
    "CQL = False\n",
    "stacked_input = 'SAR' in PATH\n",
    "\n",
    "NUMBER_OF_TRAIN_DATA = 100\n",
    "returns_red, returns_green = [], []\n",
    "agent.eval()\n",
    "\n",
    "for i in tqdm(range(NUMBER_OF_TRAIN_DATA)):\n",
    "    obsList, actList, rewList, doneList, isRedList = [], [], [], [], []\n",
    "    times = []\n",
    "    obs = env.reset()\n",
    "    state = torch.zeros(1, env_args['hidden_size']).to(device)\n",
    "    mask = torch.ones(1,1).to(device)\n",
    "    done = False\n",
    "    agent.init_hidden(1)\n",
    "    action = 0\n",
    "    rtg = 60.\n",
    "\n",
    "    for t in count():\n",
    "        times.append(t)\n",
    "        obsList.append(obs['image'])\n",
    "        #result = policy(torch.from_numpy(obs['image']).unsqueeze(0).to(device), state, mask)\n",
    "        #action, state = result['actions'], result['states']\n",
    "\n",
    "        states = torch.from_numpy(obs['image']).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q_values = []\n",
    "            for possible_action in range(0,5):  # 5 возможных действия\n",
    "                action_tensor = torch.tensor([[[possible_action]]], \n",
    "                                           dtype=torch.float32, \n",
    "                                           device=device).long()\n",
    "                rtg_tensor = torch.tensor([[[rtg]]], \n",
    "                                           dtype=torch.float32, \n",
    "                                           device=device)#.long()\n",
    "                if CQL:\n",
    "                    update_lstm_hidden = possible_action==4\n",
    "                else:\n",
    "                    update_lstm_hidden = True\n",
    "                    \n",
    "                action_preds, q1, q2, _ = agent.forward(\n",
    "                    states = states,\n",
    "                    actions = action_tensor,\n",
    "                    returns_to_go = rtg_tensor,\n",
    "                    update_hidden = update_lstm_hidden,\n",
    "                    stacked_input = stacked_input,\n",
    "                )\n",
    "                q_value = torch.minimum(q1, q2)\n",
    "                q_values.append(q_value)\n",
    "\n",
    "                if not CQL:\n",
    "                    break\n",
    "\n",
    "            # Select action with max Q-value\n",
    "            if CQL:\n",
    "                q_values = torch.cat(q_values, dim=-1)\n",
    "                action = torch.argmax(q_values).item() #+ 3\n",
    "            else:\n",
    "                action = torch.argmax(torch.softmax(action_preds, dim=-1).squeeze()).item()\n",
    "\n",
    "        #action = random.choice([3,4])\n",
    "        #print(t,action, q_values)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rtg -= reward\n",
    "\n",
    "        is_red = info['is_red']\n",
    "        rewList.append(reward)\n",
    "        actList.append(action)\n",
    "        doneList.append(int(done))\n",
    "        isRedList.append(is_red)\n",
    "\n",
    "        if done or t == EPISODE_TIMEOUT-1:\n",
    "\n",
    "            if is_red == 1.0:\n",
    "                returns_red.append(np.sum(rewList))\n",
    "            else:\n",
    "                returns_green.append(np.sum(rewList))\n",
    "\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f2f73e-c020-42f0-aaa0-611e1b32db83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.575116279069775\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(returns_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34900642-c294-4dda-a129-c9c80461348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.78526315789474\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(returns_green))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6e70f32-d56e-47a6-9f86-c488b7d54ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC S\n",
    "# 20.574042553191493\n",
    "# 20.609433962264156\n",
    "\n",
    "# BC SAR\n",
    "# 5.929761904761905\n",
    "# 6.481379310344828\n",
    "\n",
    "# CQL S\n",
    "# 22.045434782608698\n",
    "# 27.417037037037034\n",
    "\n",
    "# CQL SAR\n",
    "# 4.904339622641509\n",
    "# 5.614893617021276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d9e410d-ff38-495e-be9b-f9df0b89093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:22<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for checkpoint 99:\n",
      "Red team average return:   36.28\n",
      "Green team average return: 73.71\n",
      "Total average return:      55.74\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:59<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for checkpoint 99:\n",
      "Red team average return:   23.96\n",
      "Green team average return: 77.50\n",
      "Total average return:      52.33\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:03<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for checkpoint 99:\n",
      "Red team average return:   25.21\n",
      "Green team average return: 59.70\n",
      "Total average return:      42.11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:54<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for checkpoint 99:\n",
      "Red team average return:   40.58\n",
      "Green team average return: 41.17\n",
      "Total average return:      40.91\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:41<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for checkpoint 99:\n",
      "Red team average return:   9.84\n",
      "Green team average return: 41.12\n",
      "Total average return:      26.11\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:24<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for checkpoint 99:\n",
      "Red team average return:   38.78\n",
      "Green team average return: 49.66\n",
      "Total average return:      44.44\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6+1):\n",
    "    # PATH = f'Doom_lstm_S_90_CQL'\n",
    "    # PATH = f'ckpt/{i}/Doom_lstm_S_90_CQL'\n",
    "    PATH = f'ckpt/{i}/Doom_lstm_S_90_BC'\n",
    "    # PATH = f'Doom_lstm_SAR_90_CQL'\n",
    "\n",
    "    weights = torch.load(f\"{PATH}.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "    agent.load_state_dict(weights, strict=True)\n",
    "    agent.train()\n",
    "    agent.to(agent.device)\n",
    "\n",
    "\n",
    "    EPISODE_TIMEOUT = 4200 # 90\n",
    "    CQL = False\n",
    "    stacked_input = 'SAR' in PATH\n",
    "\n",
    "    NUMBER_OF_TRAIN_DATA = 100\n",
    "    returns_red, returns_green, returns_total = [], [], []\n",
    "    agent.eval()\n",
    "\n",
    "    for i in tqdm(range(NUMBER_OF_TRAIN_DATA)):\n",
    "        obsList, actList, rewList, doneList, isRedList = [], [], [], [], []\n",
    "        times = []\n",
    "        obs = env.reset()\n",
    "        state = torch.zeros(1, env_args['hidden_size']).to(device)\n",
    "        mask = torch.ones(1,1).to(device)\n",
    "        done = False\n",
    "        agent.init_hidden(1)\n",
    "        action = 0\n",
    "        rtg = 60.\n",
    "\n",
    "        for t in count():\n",
    "            times.append(t)\n",
    "            obsList.append(obs['image'])\n",
    "            #result = policy(torch.from_numpy(obs['image']).unsqueeze(0).to(device), state, mask)\n",
    "            #action, state = result['actions'], result['states']\n",
    "\n",
    "            states = torch.from_numpy(obs['image']).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                q_values = []\n",
    "                for possible_action in range(0,5):  # 5 возможных действия\n",
    "                    action_tensor = torch.tensor([[[possible_action]]], \n",
    "                                            dtype=torch.float32, \n",
    "                                            device=device).long()\n",
    "                    rtg_tensor = torch.tensor([[[rtg]]], \n",
    "                                            dtype=torch.float32, \n",
    "                                            device=device)#.long()\n",
    "                    if CQL:\n",
    "                        update_lstm_hidden = possible_action==4\n",
    "                    else:\n",
    "                        update_lstm_hidden = True\n",
    "                        \n",
    "                    action_preds, q1, q2, _ = agent.forward(\n",
    "                        states = states,\n",
    "                        actions = action_tensor,\n",
    "                        returns_to_go = rtg_tensor,\n",
    "                        update_hidden = update_lstm_hidden,\n",
    "                        stacked_input = stacked_input,\n",
    "                    )\n",
    "                    q_value = torch.minimum(q1, q2)\n",
    "                    q_values.append(q_value)\n",
    "\n",
    "                    if not CQL:\n",
    "                        break\n",
    "\n",
    "                # Select action with max Q-value\n",
    "                if CQL:\n",
    "                    q_values = torch.cat(q_values, dim=-1)\n",
    "                    action = torch.argmax(q_values).item() #+ 3\n",
    "                else:\n",
    "                    action = torch.argmax(torch.softmax(action_preds, dim=-1).squeeze()).item()\n",
    "\n",
    "            #action = random.choice([3,4])\n",
    "            #print(t,action, q_values)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            rtg -= reward\n",
    "\n",
    "            is_red = info['is_red']\n",
    "            rewList.append(reward)\n",
    "            actList.append(action)\n",
    "            doneList.append(int(done))\n",
    "            isRedList.append(is_red)\n",
    "\n",
    "            if done or t == EPISODE_TIMEOUT-1:\n",
    "\n",
    "                if is_red == 1.0:\n",
    "                    returns_red.append(np.sum(rewList))\n",
    "                else:\n",
    "                    returns_green.append(np.sum(rewList))\n",
    "\n",
    "                returns_total.append(np.sum(rewList))\n",
    "\n",
    "                break\n",
    "\n",
    "    print(f\"\\nResults for checkpoint {i}:\")\n",
    "    print(f\"Red team average return:   {np.mean(returns_red):.2f}\")\n",
    "    print(f\"Green team average return: {np.mean(returns_green):.2f}\")\n",
    "    print(f\"Total average return:      {np.mean(returns_total):.2f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770dc13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERSERK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
