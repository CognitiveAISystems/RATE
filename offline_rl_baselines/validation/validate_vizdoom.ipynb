{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "from lstm_agent_cql_bc import DecisionLSTM\n",
    "import yaml\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from VizDoom.VizDoom_src.utils import z_normalize, inverse_z_normalize\n",
    "from VizDoom.VizDoom_src.utils import env_vizdoom2\n",
    "from TMaze_new.TMaze_new_src.utils import set_seed\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "#import env_vizdoom2\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count\n",
    "import time\n",
    "import random\n",
    "from scipy.stats import sem\n",
    "\n",
    "env_args = {\n",
    "    'simulator':'doom', \n",
    "    'scenario':'custom_scenario{:003}.cfg', #custom_scenario{:003}.cfg\n",
    "    'test_scenario':'', \n",
    "    'screen_size':'320X180', \n",
    "    'screen_height':64, \n",
    "    'screen_width':112, \n",
    "    'num_environments':16,# 16\n",
    "    'limit_actions':True, \n",
    "    'scenario_dir':'../../VizDoom/VizDoom_src/env/', \n",
    "    'test_scenario_dir':'', \n",
    "    'show_window':False, \n",
    "    'resize':True, \n",
    "    'multimaze':True, \n",
    "    'num_mazes_train':16, \n",
    "    'num_mazes_test':1, # 64 \n",
    "    'disable_head_bob':False, \n",
    "    'use_shaping':False, \n",
    "    'fixed_scenario':False, \n",
    "    'use_pipes':False, \n",
    "    'num_actions':0, \n",
    "    'hidden_size':128, \n",
    "    'reload_model':'', \n",
    "    'model_checkpoint':'../3dcdrl/saved_models/two_col_p1_checkpoint_0198658048.pth.tar',\n",
    "    'conv1_size':16, \n",
    "    'conv2_size':32, \n",
    "    'conv3_size':16, \n",
    "    'learning_rate':0.0007, \n",
    "    'momentum':0.0, \n",
    "    'gamma':0.99, \n",
    "    'frame_skip':4, \n",
    "    'train_freq':4, \n",
    "    'train_report_freq':100, \n",
    "    'max_iters':5000000, \n",
    "    'eval_freq':1000, \n",
    "    'eval_games':50, \n",
    "    'model_save_rate':1000, \n",
    "    'eps':1e-05, \n",
    "    'alpha':0.99, \n",
    "    'use_gae':False, \n",
    "    'tau':0.95, \n",
    "    'entropy_coef':0.001, \n",
    "    'value_loss_coef':0.5, \n",
    "    'max_grad_norm':0.5, \n",
    "    'num_steps':128, \n",
    "    'num_stack':1, \n",
    "    'num_frames':200000000, \n",
    "    'use_em_loss':False, \n",
    "    'skip_eval':False, \n",
    "    'stoc_evals':False, \n",
    "    'model_dir':'', \n",
    "    'out_dir':'./', \n",
    "    'log_interval':100, \n",
    "    'job_id':12345, \n",
    "    'test_name':'test_000', \n",
    "    'use_visdom':False, \n",
    "    'visdom_port':8097, \n",
    "    'visdom_ip':'http://10.0.0.1'                 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(seed, exp_name, loss_mode, stacked_input):\n",
    "    agent = DecisionLSTM(4, 1, 128, mode='doom')\n",
    "    \n",
    "    run_name = f'{exp_name}_{loss_mode}_{seed}_stacked_{stacked_input}'\n",
    "    print(run_name)\n",
    "    model_path = f'../ckpt/vizdoom_ckpt/{loss_mode}/{seed}/{run_name}.ckpt'\n",
    "    \n",
    "    agent.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    agent.eval()\n",
    "    agent.to(agent.device)\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../VizDoom/VizDoom_notebooks/')\n",
    "from VizDoom.VizDoom_notebooks.doom_environment2 import DoomEnvironment\n",
    "import env_vizdoom2\n",
    "\n",
    "scene = 0\n",
    "scenario = env_args['scenario_dir'] + env_args['scenario'].format(scene) # 0 % 63\n",
    "config = scenario\n",
    "device = 'cuda:0'\n",
    "\n",
    "env = env_vizdoom2.DoomEnvironmentDisappear(\n",
    "    scenario=config,\n",
    "    show_window=False,\n",
    "    use_info=True,\n",
    "    use_shaping=False, #if False bonus reward if #shaping reward is always: +1,-1 in two_towers\n",
    "    frame_skip=2,\n",
    "    no_backward_movement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'doom'\n",
    "stacked_input = False\n",
    "loss_mode = 'bc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doom_bc_1_stacked_False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': array([[[  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [159, 159, 159, ...,  35,  27,  27],\n",
      "        [159, 159, 159, ...,  35,  27,  27],\n",
      "        [159, 159, 159, ...,  35,  27,  27]],\n",
      "\n",
      "       [[  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [159, 159, 159, ...,  35,  27,  27],\n",
      "        [159, 159, 159, ...,  35,  27,  27],\n",
      "        [159, 159, 159, ...,  35,  27,  27]],\n",
      "\n",
      "       [[ 22,  11,  11, ...,  22,  12,  22],\n",
      "        [ 19,  21,  13, ...,  12,  30,  20],\n",
      "        [ 23,  17,  19, ...,  13,  23,  16],\n",
      "        ...,\n",
      "        [159, 159, 159, ...,  35,  27,  27],\n",
      "        [159, 159, 159, ...,  35,  27,  27],\n",
      "        [159, 159, 159, ...,  35,  27,  27]]], dtype=uint8), 'health': 92.0, 'shaping_reward': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:04<07:35,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': array([[[  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 31,  28,  20, ...,  19,  24,  36],\n",
      "        [ 22,  25,  25, ...,  19,  21,  50],\n",
      "        [ 15,  11,   9, ...,  23,  34,  39]],\n",
      "\n",
      "       [[  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 68,  61,  38, ...,  35,  54,  76],\n",
      "        [ 44,  55,  52, ...,  35,  43, 105],\n",
      "        [ 24,  23,  14, ...,  51,  74,  83]],\n",
      "\n",
      "       [[ 22,  11,  11, ...,  22,  12,  22],\n",
      "        [ 19,  21,  13, ...,  12,  30,  20],\n",
      "        [ 23,  17,  19, ...,  13,  23,  16],\n",
      "        ...,\n",
      "        [ 21,  20,  12, ...,  11,  16,  25],\n",
      "        [ 14,  17,  15, ...,  11,  13,  38],\n",
      "        [  1,   7,   7, ...,  15,  26,  27]]], dtype=uint8), 'health': 92.0, 'shaping_reward': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:05<09:13,  5.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     update_lstm_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m action_preds, q1, q2, _ \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maction_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturns_to_go\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrtg_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_hidden\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mupdate_lstm_hidden\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstacked_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstacked_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m q_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mminimum(q1, q2)\n\u001b[1;32m     73\u001b[0m q_values\u001b[38;5;241m.\u001b[39mappend(q_value)\n",
      "File \u001b[0;32m~/Egor_C/REPOSITORIES/rate_maniskill/RATE/offline_rl_baselines/validation/../lstm_agent_cql_bc.py:186\u001b[0m, in \u001b[0;36mDecisionLSTM.forward\u001b[0;34m(self, states, actions, returns_to_go, attention_mask, update_hidden, stacked_input)\u001b[0m\n\u001b[1;32m    184\u001b[0m batch_size, seq_length, C, H, W \u001b[38;5;241m=\u001b[39m states\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    185\u001b[0m states \u001b[38;5;241m=\u001b[39m states\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, C, H, W)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mcontiguous() \n\u001b[0;32m--> 186\u001b[0m state_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(batch_size, seq_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminigrid_memory\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    189\u001b[0m     actions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(actions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m3\u001b[39m), actions)\n",
      "File \u001b[0;32m~/.mlspace/envs/BERSERK/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.mlspace/envs/BERSERK/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.mlspace/envs/BERSERK/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.mlspace/envs/BERSERK/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.mlspace/envs/BERSERK/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.mlspace/envs/BERSERK/lib/python3.11/site-packages/torch/nn/modules/activation.py:356\u001b[0m, in \u001b[0;36mTanh.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "totals, reds, greens = [], [], []\n",
    "\n",
    "for i in range(1, 6+1):\n",
    "    agent = load_model(\n",
    "        seed=i,\n",
    "        exp_name=exp_name,\n",
    "        stacked_input=stacked_input,\n",
    "        loss_mode=loss_mode, \n",
    "    )\n",
    "\n",
    "    _ = agent.eval()\n",
    "    _ = agent.to(agent.device)\n",
    "    PATH = f'../vizdoom_ckpt/{loss_mode}/{i}/{exp_name}_{loss_mode}_{i}_stacked_{stacked_input}.ckpt'\n",
    "    # PATH = f'Doom_lstm_SAR_90_CQL'\n",
    "\n",
    "    # weights = torch.load(f\"{PATH}.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "    # agent.load_state_dict(weights, strict=True)\n",
    "    # agent.train()\n",
    "    # agent.to(agent.device)\n",
    "\n",
    "\n",
    "    EPISODE_TIMEOUT = 4200 # 90\n",
    "\n",
    "    NUMBER_OF_TRAIN_DATA = 100\n",
    "    returns_red, returns_green, returns_total = [], [], []\n",
    "    agent.eval()\n",
    "\n",
    "    for i in tqdm(range(NUMBER_OF_TRAIN_DATA)):\n",
    "        obsList, actList, rewList, doneList, isRedList = [], [], [], [], []\n",
    "        times = []\n",
    "        obs = env.reset()\n",
    "        # plt.imshow(obs['image'].transpose(1,2,0))\n",
    "        # plt.show()\n",
    "        state = torch.zeros(1, env_args['hidden_size']).to(device)\n",
    "        mask = torch.ones(1,1).to(device)\n",
    "        done = False\n",
    "        agent.init_hidden(1)\n",
    "        action = 0\n",
    "        rtg = 56.5\n",
    "\n",
    "        for t in count():\n",
    "            times.append(t)\n",
    "            obsList.append(obs['image'])\n",
    "            #result = policy(torch.from_numpy(obs['image']).unsqueeze(0).to(device), state, mask)\n",
    "            #action, state = result['actions'], result['states']\n",
    "\n",
    "            states = torch.from_numpy(obs['image']).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                q_values = []\n",
    "                for possible_action in range(0, 5):  # 5 возможных действия\n",
    "                    action_tensor = torch.tensor([[[possible_action]]], \n",
    "                                            dtype=torch.float32, \n",
    "                                            device=device).long()\n",
    "                    rtg_tensor = torch.tensor([[[rtg]]], \n",
    "                                            dtype=torch.float32, \n",
    "                                            device=device)#.long()\n",
    "                    if loss_mode == 'cql':\n",
    "                        update_lstm_hidden = possible_action==4\n",
    "                    else:\n",
    "                        update_lstm_hidden = True\n",
    "                        \n",
    "                    action_preds, q1, q2, _ = agent.forward(\n",
    "                        states = states,\n",
    "                        actions = action_tensor,\n",
    "                        returns_to_go = rtg_tensor,\n",
    "                        update_hidden = update_lstm_hidden,\n",
    "                        stacked_input = stacked_input,\n",
    "                    )\n",
    "                    q_value = torch.minimum(q1, q2)\n",
    "                    q_values.append(q_value)\n",
    "\n",
    "                    if not loss_mode == 'cql':\n",
    "                        break\n",
    "\n",
    "                # Select action with max Q-value\n",
    "                if loss_mode == 'cql':\n",
    "                    q_values = torch.cat(q_values, dim=-1)\n",
    "                    action = torch.argmax(q_values).item() #+ 3\n",
    "                else:\n",
    "                    action = torch.argmax(torch.softmax(action_preds, dim=-1).squeeze()).item()\n",
    "\n",
    "            #action = random.choice([3,4])\n",
    "            #print(t,action, q_values)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            rtg -= reward\n",
    "\n",
    "            is_red = info['is_red']\n",
    "            rewList.append(reward)\n",
    "            actList.append(action)\n",
    "            doneList.append(int(done))\n",
    "            isRedList.append(is_red)\n",
    "\n",
    "            if done or t == EPISODE_TIMEOUT-1:\n",
    "\n",
    "                if is_red == 1.0:\n",
    "                    returns_red.append(np.sum(rewList))\n",
    "                else:\n",
    "                    returns_green.append(np.sum(rewList))\n",
    "\n",
    "                returns_total.append(np.sum(rewList))\n",
    "\n",
    "                break\n",
    "\n",
    "    print(f\"\\nResults for checkpoint {i}:\")\n",
    "    print(f\"Red team average return:   {np.mean(returns_red):.2f}\")\n",
    "    print(f\"Green team average return: {np.mean(returns_green):.2f}\")\n",
    "    print(f\"Total average return:      {np.mean(returns_total):.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    totals.append(np.mean(returns_total))\n",
    "    reds.append(np.mean(returns_red))\n",
    "    greens.append(np.mean(returns_green))\n",
    "\n",
    "print('\\n')\n",
    "print('#'*50)\n",
    "\n",
    "print(f'TOTAL: {np.mean(totals)} ± {sem(totals)}')\n",
    "print(f'RED: {np.mean(reds)} ± {sem(reds)}')\n",
    "print(f'GREEN: {np.mean(greens)} ± {sem(greens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
